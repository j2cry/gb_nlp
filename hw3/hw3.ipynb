{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "К сожалению, у меня не хватит времени прикрутить сюда распределенную обработку, поэтому в работе использую только часть данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/avagadro/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/avagadro/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "import pymorphy2 as pm2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from gensim.models import Word2Vec, FastText\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from joblib import parallel_backend, Parallel, delayed\n",
    "\n",
    "from tqdm import tqdm\n",
    "from ast import literal_eval\n",
    "from sklearn.metrics import pairwise_distances, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from annoy import AnnoyIndex\n",
    "\n",
    "import torch\n",
    "from sklearn.mixture import BayesianGaussianMixture, GaussianMixture\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__load data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>topic</th>\n",
       "      <th>tags</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://lenta.ru/news/1914/09/16/hungarnn/</td>\n",
       "      <td>1914. Русские войска вступили в пределы Венгрии</td>\n",
       "      <td>Бои у Сопоцкина и Друскеник закончились отступ...</td>\n",
       "      <td>Библиотека</td>\n",
       "      <td>Первая мировая</td>\n",
       "      <td>1914/09/16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://lenta.ru/news/1914/09/16/lermontov/</td>\n",
       "      <td>1914. Празднование столетия М.Ю. Лермонтова от...</td>\n",
       "      <td>Министерство народного просвещения, в виду про...</td>\n",
       "      <td>Библиотека</td>\n",
       "      <td>Первая мировая</td>\n",
       "      <td>1914/09/16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://lenta.ru/news/1914/09/17/nesteroff/</td>\n",
       "      <td>1914. Das ist Nesteroff!</td>\n",
       "      <td>Штабс-капитан П. Н. Нестеров на днях, увидев в...</td>\n",
       "      <td>Библиотека</td>\n",
       "      <td>Первая мировая</td>\n",
       "      <td>1914/09/17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://lenta.ru/news/1914/09/17/bulldogn/</td>\n",
       "      <td>1914. Бульдог-гонец под Льежем</td>\n",
       "      <td>Фотограф-корреспондент Daily Mirror рассказыва...</td>\n",
       "      <td>Библиотека</td>\n",
       "      <td>Первая мировая</td>\n",
       "      <td>1914/09/17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://lenta.ru/news/1914/09/18/zver/</td>\n",
       "      <td>1914. Под Люблином пойман швабский зверь</td>\n",
       "      <td>Лица, приехавшие в Варшаву из Люблина, передаю...</td>\n",
       "      <td>Библиотека</td>\n",
       "      <td>Первая мировая</td>\n",
       "      <td>1914/09/18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           url  \\\n",
       "0   https://lenta.ru/news/1914/09/16/hungarnn/   \n",
       "1  https://lenta.ru/news/1914/09/16/lermontov/   \n",
       "2  https://lenta.ru/news/1914/09/17/nesteroff/   \n",
       "3   https://lenta.ru/news/1914/09/17/bulldogn/   \n",
       "4       https://lenta.ru/news/1914/09/18/zver/   \n",
       "\n",
       "                                               title  \\\n",
       "0  1914. Русские войска вступили в пределы Венгрии     \n",
       "1  1914. Празднование столетия М.Ю. Лермонтова от...   \n",
       "2                           1914. Das ist Nesteroff!   \n",
       "3                    1914. Бульдог-гонец под Льежем    \n",
       "4           1914. Под Люблином пойман швабский зверь   \n",
       "\n",
       "                                                text       topic  \\\n",
       "0  Бои у Сопоцкина и Друскеник закончились отступ...  Библиотека   \n",
       "1  Министерство народного просвещения, в виду про...  Библиотека   \n",
       "2  Штабс-капитан П. Н. Нестеров на днях, увидев в...  Библиотека   \n",
       "3  Фотограф-корреспондент Daily Mirror рассказыва...  Библиотека   \n",
       "4  Лица, приехавшие в Варшаву из Люблина, передаю...  Библиотека   \n",
       "\n",
       "             tags        date  \n",
       "0  Первая мировая  1914/09/16  \n",
       "1  Первая мировая  1914/09/16  \n",
       "2  Первая мировая  1914/09/17  \n",
       "3  Первая мировая  1914/09/17  \n",
       "4  Первая мировая  1914/09/18  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news = pd.read_csv('data/lenta-ru-news.csv', dtype={'topic': str})\n",
    "news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 800975 entries, 0 to 800974\n",
      "Data columns (total 6 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   url     800975 non-null  object\n",
      " 1   title   800975 non-null  object\n",
      " 2   text    800970 non-null  object\n",
      " 3   topic   738973 non-null  object\n",
      " 4   tags    773756 non-null  object\n",
      " 5   date    800975 non-null  object\n",
      "dtypes: object(6)\n",
      "memory usage: 36.7+ MB\n"
     ]
    }
   ],
   "source": [
    "news.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__preprocessing__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обрабатывать обучающие данные проще пайплайном, но для единичных пользовательских запросов пайплайн в реализованном виде не очень удобен,\n",
    "т.к. требует конвертации в pd.DataFrame.\n",
    "\n",
    "Оптимальное решение пока не нашел, и чтобы не писать тут одни и те же предобработки, пользуюсь конвертацией единичного запроса. В проде такое, на мой взгляд, недопустимо."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicTransformer(TransformerMixin):\n",
    "    def __init__(self, fields, **kwargs):\n",
    "        self.fields = fields if isinstance(fields, list) else [fields]\n",
    "        self.backend = kwargs.pop('backend', 'loky')\n",
    "        self.n_jobs = kwargs.pop('n_jobs', -1)\n",
    "        for key, value in kwargs.items():\n",
    "            setattr(self, key, value)\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        if 'all' in self.fields:\n",
    "            self.fields = X.columns\n",
    "        self.fields = [col for col in self.fields if col in X.columns]\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        for f in self.fields:\n",
    "            X[f] = self.transform_column(X[f])\n",
    "        return X\n",
    "    \n",
    "    def transform_column(self, column):\n",
    "        return column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lowercase(BasicTransformer):\n",
    "    def transform_column(self, column):\n",
    "        print(f'Lowercase `{column.name}`')\n",
    "        return column.str.lower()\n",
    "\n",
    "class CutRegexp(BasicTransformer):\n",
    "    def transform_column(self, column):\n",
    "        print(f'Cut regexp `{column.name}`')\n",
    "        return column.str.replace(self.pattern, self.fill, regex=True)\n",
    "\n",
    "class Tokenize(BasicTransformer):\n",
    "    def transform_column(self, column):\n",
    "        with parallel_backend(self.backend, n_jobs=self.n_jobs):\n",
    "            result = Parallel()(delayed(self.tokenizer)(row) for row in tqdm(column.values, desc=f'tokenize `{column.name}`'))\n",
    "        return result\n",
    "\n",
    "class ClearStopwords(BasicTransformer):\n",
    "    def transform_column(self, column):\n",
    "        def _drop_stopwords(tokens):\n",
    "            # return [w for w in tokens if w not in self.stopwords]     # NOTE проверить, какой вариант быстрее\n",
    "            return list(set(tokens).difference(self.stopwords))\n",
    "\n",
    "        with parallel_backend(self.backend, n_jobs=self.n_jobs):\n",
    "            result = Parallel()(delayed(_drop_stopwords)(row) for row in tqdm(column.values, desc=f'clearing `{column.name}`'))\n",
    "        return result\n",
    "        # return column.apply(lambda tokens: [w for w in tokens if w not in self.stopwords])\n",
    "\n",
    "class Lemmatize(BasicTransformer):\n",
    "    morph = pm2.MorphAnalyzer()\n",
    "    def transform_column(self, column):\n",
    "        def _lemma(tokens):\n",
    "            return [self.morph.parse(w)[0].normal_form for w in tokens]\n",
    "\n",
    "        with parallel_backend(self.backend, n_jobs=self.n_jobs):\n",
    "            result = Parallel()(delayed(_lemma)(row) for row in tqdm(column.values, desc=f'lemmatize `{column.name}`'))\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init pipeline\n",
    "fields = ['title', 'text']\n",
    "pipeline = make_pipeline(\n",
    "    Lowercase(fields),\n",
    "    CutRegexp(fields, pattern=r'\\W|\\d', fill=' '),      # убрать спецсимволы и цифры\n",
    "    Tokenize(fields, tokenizer=nltk.tokenize.word_tokenize),\n",
    "    ClearStopwords(fields, stopwords=nltk.corpus.stopwords.words('russian')),\n",
    "    Lemmatize(fields)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare masks\n",
    "nans = news['text'].isna() | news['title'].isna()       # drop nan\n",
    "short = news['text'].str.split().str.len() < 10         # drop short texts - это очень тяжелая операция\n",
    "\n",
    "topics_mask = news['topic'].value_counts() > 5000       # select data with most frequent topics - это, опять же, для упрощения задачи\n",
    "topics = news['topic'].value_counts()[topics_mask].index\n",
    "use_topics = news['topic'].isin(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lowercase `title`\n",
      "Lowercase `text`\n",
      "Cut regexp `title`\n",
      "Cut regexp `text`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenize `title`: 100%|██████████| 25000/25000 [00:00<00:00, 49361.25it/s]\n",
      "tokenize `text`: 100%|██████████| 25000/25000 [00:04<00:00, 5860.22it/s]\n",
      "clearing `title`: 100%|██████████| 25000/25000 [00:02<00:00, 8793.43it/s]\n",
      "clearing `text`: 100%|██████████| 25000/25000 [00:01<00:00, 13610.60it/s]\n",
      "lemmatize `title`: 100%|██████████| 25000/25000 [11:18<00:00, 36.87it/s]\n",
      "lemmatize `text`: 100%|██████████| 25000/25000 [07:29<00:00, 55.56it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>topic</th>\n",
       "      <th>tags</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69783</th>\n",
       "      <td>https://lenta.ru/news/2003/04/23/teacher/</td>\n",
       "      <td>[хорватский, библиотека, домашний, учитель, ед...</td>\n",
       "      <td>[сосед, госпитализация, сообщать, ananova, пре...</td>\n",
       "      <td>Из жизни</td>\n",
       "      <td>Все</td>\n",
       "      <td>2003/04/23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69373</th>\n",
       "      <td>https://lenta.ru/news/2003/04/15/syria/</td>\n",
       "      <td>[буш, готовить, запретить, война, пентагон, си...</td>\n",
       "      <td>[вашингтон, эпизод, принятие, новый, однако, г...</td>\n",
       "      <td>Мир</td>\n",
       "      <td>Все</td>\n",
       "      <td>2003/04/15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722211</th>\n",
       "      <td>https://lenta.ru/news/2018/08/02/latte_for_pre...</td>\n",
       "      <td>[беременный, средство, вместо, кофе, канадка, ...</td>\n",
       "      <td>[чистить, развесить, заявить, однако, франчайз...</td>\n",
       "      <td>Из жизни</td>\n",
       "      <td>Люди</td>\n",
       "      <td>2018/08/02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240806</th>\n",
       "      <td>https://lenta.ru/news/2008/08/08/mechel1/</td>\n",
       "      <td>[акция, перенести, размещение, мечел, второй]</td>\n",
       "      <td>[потерять, акция, наметить, доллар, металлурги...</td>\n",
       "      <td>Экономика</td>\n",
       "      <td>Все</td>\n",
       "      <td>2008/08/08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190561</th>\n",
       "      <td>https://lenta.ru/news/2007/05/29/nba/</td>\n",
       "      <td>[вылет, оказаться, плей, андрей, ют, кириленко...</td>\n",
       "      <td>[сперс, забить, сборная, официальный, чужой, к...</td>\n",
       "      <td>Спорт</td>\n",
       "      <td>Все</td>\n",
       "      <td>2007/05/29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      url  \\\n",
       "69783           https://lenta.ru/news/2003/04/23/teacher/   \n",
       "69373             https://lenta.ru/news/2003/04/15/syria/   \n",
       "722211  https://lenta.ru/news/2018/08/02/latte_for_pre...   \n",
       "240806          https://lenta.ru/news/2008/08/08/mechel1/   \n",
       "190561              https://lenta.ru/news/2007/05/29/nba/   \n",
       "\n",
       "                                                    title  \\\n",
       "69783   [хорватский, библиотека, домашний, учитель, ед...   \n",
       "69373   [буш, готовить, запретить, война, пентагон, си...   \n",
       "722211  [беременный, средство, вместо, кофе, канадка, ...   \n",
       "240806      [акция, перенести, размещение, мечел, второй]   \n",
       "190561  [вылет, оказаться, плей, андрей, ют, кириленко...   \n",
       "\n",
       "                                                     text      topic  tags  \\\n",
       "69783   [сосед, госпитализация, сообщать, ananova, пре...   Из жизни   Все   \n",
       "69373   [вашингтон, эпизод, принятие, новый, однако, г...        Мир   Все   \n",
       "722211  [чистить, развесить, заявить, однако, франчайз...   Из жизни  Люди   \n",
       "240806  [потерять, акция, наметить, доллар, металлурги...  Экономика   Все   \n",
       "190561  [сперс, забить, сборная, официальный, чужой, к...      Спорт   Все   \n",
       "\n",
       "              date  \n",
       "69783   2003/04/23  \n",
       "69373   2003/04/15  \n",
       "722211  2018/08/02  \n",
       "240806  2008/08/08  \n",
       "190561  2007/05/29  "
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preprocess data sample: поскольку времени мало, беру очень маленькую часть данных\n",
    "data = news[~nans & ~short & use_topics].sample(25000, random_state=23)\n",
    "\n",
    "prepared = pipeline.fit_transform(data)\n",
    "prepared.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared.to_csv('data/prepared.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load saved\n",
    "prepared = pd.read_csv('data/prepared.csv', index_col='Unnamed: 0', converters={'title': literal_eval, 'text': literal_eval})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lowercase `title`\n",
      "Cut regexp `title`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenize `title`: 100%|██████████| 1/1 [00:00<00:00, 729.70it/s]\n",
      "clearing `title`: 100%|██████████| 1/1 [00:00<00:00, 480.28it/s]\n",
      "lemmatize `title`: 100%|██████████| 1/1 [00:00<00:00, 1190.89it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[достижение, спортивный]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      title\n",
       "0  [достижение, спортивный]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "field = 'title'\n",
    "# field = 'text'\n",
    "sentences = prepared[field]\n",
    "\n",
    "# request preprocess\n",
    "request_text = 'спортивные достижения'\n",
    "request = pipeline.fit_transform(pd.DataFrame([request_text], columns=[field]))\n",
    "request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__word2vec__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>topic</th>\n",
       "      <th>tags</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20774</th>\n",
       "      <td>https://lenta.ru/news/2001/01/29/diplomat/</td>\n",
       "      <td>Канада требует выдачи российских дипломатов, у...</td>\n",
       "      <td>Канада обратилась к России с просьбой лишить д...</td>\n",
       "      <td>Мир</td>\n",
       "      <td>Все</td>\n",
       "      <td>2001/01/29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18277</th>\n",
       "      <td>https://lenta.ru/news/2000/12/14/opros/</td>\n",
       "      <td>Доверие к доллару в России падает</td>\n",
       "      <td>Число россиян - сторонников доллара и другой и...</td>\n",
       "      <td>Экономика</td>\n",
       "      <td>Все</td>\n",
       "      <td>2000/12/14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2933</th>\n",
       "      <td>https://lenta.ru/news/1999/12/27/chaos/</td>\n",
       "      <td>В Берлине открывается конгресс Chaos Computer ...</td>\n",
       "      <td>В понедельник в Берлине открывается шестнадцат...</td>\n",
       "      <td>Интернет и СМИ</td>\n",
       "      <td>Все</td>\n",
       "      <td>1999/12/27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12217</th>\n",
       "      <td>https://lenta.ru/news/2000/08/31/robot/</td>\n",
       "      <td>Роботы научились ползать и размножаться</td>\n",
       "      <td>Ученые из Brandeis University в Массачусеттсе ...</td>\n",
       "      <td>Интернет и СМИ</td>\n",
       "      <td>Все</td>\n",
       "      <td>2000/08/31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23574</th>\n",
       "      <td>https://lenta.ru/news/2001/03/19/insects/</td>\n",
       "      <td>Лондонские гурманы перешли на насекомых в шоко...</td>\n",
       "      <td>Среди лондонцев все популярнее делается новое ...</td>\n",
       "      <td>Из жизни</td>\n",
       "      <td>Все</td>\n",
       "      <td>2001/03/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18781</th>\n",
       "      <td>https://lenta.ru/news/2000/12/22/ethics/</td>\n",
       "      <td>Депутат избил водителя. Теперь его будут судит...</td>\n",
       "      <td>Около четырехсот жалоб на поведение депутатов ...</td>\n",
       "      <td>Россия</td>\n",
       "      <td>Все</td>\n",
       "      <td>2000/12/22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13413</th>\n",
       "      <td>https://lenta.ru/news/2000/09/23/shooting/</td>\n",
       "      <td>Преступники расстреляли жертву на оживленной у...</td>\n",
       "      <td>В субботу около 15 часов у дома 27 по улице Кр...</td>\n",
       "      <td>Россия</td>\n",
       "      <td>Все</td>\n",
       "      <td>2000/09/23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1387</th>\n",
       "      <td>https://lenta.ru/news/1999/11/02/wood/</td>\n",
       "      <td>Китайскую внешнюю торговлю разъедают жуки-короеды</td>\n",
       "      <td>Миллиарды долларов инвестиций, вложенные в тор...</td>\n",
       "      <td>Экономика</td>\n",
       "      <td>Все</td>\n",
       "      <td>1999/11/02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19342</th>\n",
       "      <td>https://lenta.ru/news/2001/01/04/cz/</td>\n",
       "      <td>Чешский сенат стал на защиту тележурналистов</td>\n",
       "      <td>Верхняя палата парламента Чехии в среду вечеро...</td>\n",
       "      <td>Мир</td>\n",
       "      <td>Все</td>\n",
       "      <td>2001/01/04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20805</th>\n",
       "      <td>https://lenta.ru/news/2001/01/30/dagestan/</td>\n",
       "      <td>В депутата парламента Дагестана бросили гранату</td>\n",
       "      <td>В дагестанском городе Избербаше совершено поку...</td>\n",
       "      <td>Россия</td>\n",
       "      <td>Все</td>\n",
       "      <td>2001/01/30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              url  \\\n",
       "20774  https://lenta.ru/news/2001/01/29/diplomat/   \n",
       "18277     https://lenta.ru/news/2000/12/14/opros/   \n",
       "2933      https://lenta.ru/news/1999/12/27/chaos/   \n",
       "12217     https://lenta.ru/news/2000/08/31/robot/   \n",
       "23574   https://lenta.ru/news/2001/03/19/insects/   \n",
       "18781    https://lenta.ru/news/2000/12/22/ethics/   \n",
       "13413  https://lenta.ru/news/2000/09/23/shooting/   \n",
       "1387       https://lenta.ru/news/1999/11/02/wood/   \n",
       "19342        https://lenta.ru/news/2001/01/04/cz/   \n",
       "20805  https://lenta.ru/news/2001/01/30/dagestan/   \n",
       "\n",
       "                                                   title  \\\n",
       "20774  Канада требует выдачи российских дипломатов, у...   \n",
       "18277                  Доверие к доллару в России падает   \n",
       "2933   В Берлине открывается конгресс Chaos Computer ...   \n",
       "12217            Роботы научились ползать и размножаться   \n",
       "23574  Лондонские гурманы перешли на насекомых в шоко...   \n",
       "18781  Депутат избил водителя. Теперь его будут судит...   \n",
       "13413  Преступники расстреляли жертву на оживленной у...   \n",
       "1387   Китайскую внешнюю торговлю разъедают жуки-короеды   \n",
       "19342       Чешский сенат стал на защиту тележурналистов   \n",
       "20805    В депутата парламента Дагестана бросили гранату   \n",
       "\n",
       "                                                    text           topic tags  \\\n",
       "20774  Канада обратилась к России с просьбой лишить д...             Мир  Все   \n",
       "18277  Число россиян - сторонников доллара и другой и...       Экономика  Все   \n",
       "2933   В понедельник в Берлине открывается шестнадцат...  Интернет и СМИ  Все   \n",
       "12217  Ученые из Brandeis University в Массачусеттсе ...  Интернет и СМИ  Все   \n",
       "23574  Среди лондонцев все популярнее делается новое ...        Из жизни  Все   \n",
       "18781  Около четырехсот жалоб на поведение депутатов ...          Россия  Все   \n",
       "13413  В субботу около 15 часов у дома 27 по улице Кр...          Россия  Все   \n",
       "1387   Миллиарды долларов инвестиций, вложенные в тор...       Экономика  Все   \n",
       "19342  Верхняя палата парламента Чехии в среду вечеро...             Мир  Все   \n",
       "20805  В дагестанском городе Избербаше совершено поку...          Россия  Все   \n",
       "\n",
       "             date  \n",
       "20774  2001/01/29  \n",
       "18277  2000/12/14  \n",
       "2933   1999/12/27  \n",
       "12217  2000/08/31  \n",
       "23574  2001/03/19  \n",
       "18781  2000/12/22  \n",
       "13413  2000/09/23  \n",
       "1387   1999/11/02  \n",
       "19342  2001/01/04  \n",
       "20805  2001/01/30  "
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# word2vec init\n",
    "vecsize = 300\n",
    "w2v = Word2Vec(sentences, vector_size=vecsize, window=5, min_count=1, seed=31)\n",
    "# build embeddings\n",
    "w2v_embs = sentences.apply(lambda row: np.mean([w2v.wv[word] for word in row if word in w2v.wv], axis=0))\n",
    "\n",
    "# calc request embedding\n",
    "w2v_request_emb = request[field].apply(lambda row: np.array([w2v.wv[word] for word in row if word in w2v.wv]).mean(axis=0))\n",
    "\n",
    "# build w2v cluster map\n",
    "w2v_cluster = AnnoyIndex(vecsize ,'angular')\n",
    "for idx, item in enumerate(w2v_embs):\n",
    "    w2v_cluster.add_item(idx, item)\n",
    "\n",
    "w2v_cluster.build(10, n_jobs=-1)\n",
    "\n",
    "# get top nearest\n",
    "top = w2v_cluster.get_nns_by_vector(w2v_request_emb[0], 10)\n",
    "news.loc[top]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>topic</th>\n",
       "      <th>tags</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>610286</th>\n",
       "      <td>https://lenta.ru/news/2016/08/02/mamont/</td>\n",
       "      <td>Мамонтов добила жажда</td>\n",
       "      <td>Последняя популяция мамонтов на Земле вымерла ...</td>\n",
       "      <td>Наука и техника</td>\n",
       "      <td>Наука</td>\n",
       "      <td>2016/08/02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711456</th>\n",
       "      <td>https://lenta.ru/news/2018/05/03/poslemayskih/</td>\n",
       "      <td>Орангутан загрустил в неволе и растолстел</td>\n",
       "      <td>Орангутан из Бангкокского зоопарка в Таиланде ...</td>\n",
       "      <td>Из жизни</td>\n",
       "      <td>Звери</td>\n",
       "      <td>2018/05/03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733934</th>\n",
       "      <td>https://lenta.ru/news/2018/11/06/ronaldinho/</td>\n",
       "      <td>Роналдиньо подозрительно обеднел</td>\n",
       "      <td>Бывший полузащитник «Барселоны» и сборной Браз...</td>\n",
       "      <td>Спорт</td>\n",
       "      <td>Футбол</td>\n",
       "      <td>2018/11/06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452612</th>\n",
       "      <td>https://lenta.ru/news/2013/01/30/tezzz/</td>\n",
       "      <td>Tequilajazzz воссоединится для перезаписи «Цел...</td>\n",
       "      <td>Группа Tequilajazzz перезапишет альбом «Целлул...</td>\n",
       "      <td>Культура</td>\n",
       "      <td>Музыка</td>\n",
       "      <td>2013/01/30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180927</th>\n",
       "      <td>https://lenta.ru/news/2007/02/21/congress/</td>\n",
       "      <td>В Таллин съезжаются каббалисты</td>\n",
       "      <td>22 января в Таллине откроется Европейский конг...</td>\n",
       "      <td>Бывший СССР</td>\n",
       "      <td>Все</td>\n",
       "      <td>2007/02/21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491914</th>\n",
       "      <td>https://lenta.ru/news/2013/12/24/fbreader/</td>\n",
       "      <td>YotaPhone подружили с читалкой FBReader</td>\n",
       "      <td>Приложение для чтения электронных книг FBReade...</td>\n",
       "      <td>Наука и техника</td>\n",
       "      <td>Гаджеты</td>\n",
       "      <td>2013/12/24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112313</th>\n",
       "      <td>https://lenta.ru/economy/2005/02/11/yugansk/</td>\n",
       "      <td>\"Юганскнефтегаз\" рассчитался с Минприроды</td>\n",
       "      <td>\"Юганскнефтегаз\" уже направил в Министерство п...</td>\n",
       "      <td>Экономика</td>\n",
       "      <td>Все</td>\n",
       "      <td>2005/02/11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>https://lenta.ru/news/1999/09/07/inkombank/</td>\n",
       "      <td>\"Инкомбанк\" отстоял свою состоятельность</td>\n",
       "      <td>\"Инкомбанк\" добился приостановления дела о его...</td>\n",
       "      <td>Россия</td>\n",
       "      <td>Все</td>\n",
       "      <td>1999/09/07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288524</th>\n",
       "      <td>https://lenta.ru/news/2009/06/26/needlework/</td>\n",
       "      <td>Сикстинскую капеллу вышили крестиком</td>\n",
       "      <td>Джоанна Лопяновски-Робертс, живущая в США урож...</td>\n",
       "      <td>Культура</td>\n",
       "      <td>Все</td>\n",
       "      <td>2009/06/26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478790</th>\n",
       "      <td>https://lenta.ru/news/2013/09/06/guelman/</td>\n",
       "      <td>Гельмана выселили с «Винзавода»</td>\n",
       "      <td>Галерею «Культурный Альянс. Проект Марата Гель...</td>\n",
       "      <td>Культура</td>\n",
       "      <td>Искусство</td>\n",
       "      <td>2013/09/06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   url  \\\n",
       "610286        https://lenta.ru/news/2016/08/02/mamont/   \n",
       "711456  https://lenta.ru/news/2018/05/03/poslemayskih/   \n",
       "733934    https://lenta.ru/news/2018/11/06/ronaldinho/   \n",
       "452612         https://lenta.ru/news/2013/01/30/tezzz/   \n",
       "180927      https://lenta.ru/news/2007/02/21/congress/   \n",
       "491914      https://lenta.ru/news/2013/12/24/fbreader/   \n",
       "112313    https://lenta.ru/economy/2005/02/11/yugansk/   \n",
       "107        https://lenta.ru/news/1999/09/07/inkombank/   \n",
       "288524    https://lenta.ru/news/2009/06/26/needlework/   \n",
       "478790       https://lenta.ru/news/2013/09/06/guelman/   \n",
       "\n",
       "                                                    title  \\\n",
       "610286                              Мамонтов добила жажда   \n",
       "711456          Орангутан загрустил в неволе и растолстел   \n",
       "733934                   Роналдиньо подозрительно обеднел   \n",
       "452612  Tequilajazzz воссоединится для перезаписи «Цел...   \n",
       "180927                     В Таллин съезжаются каббалисты   \n",
       "491914            YotaPhone подружили с читалкой FBReader   \n",
       "112313          \"Юганскнефтегаз\" рассчитался с Минприроды   \n",
       "107              \"Инкомбанк\" отстоял свою состоятельность   \n",
       "288524               Сикстинскую капеллу вышили крестиком   \n",
       "478790                    Гельмана выселили с «Винзавода»   \n",
       "\n",
       "                                                     text            topic  \\\n",
       "610286  Последняя популяция мамонтов на Земле вымерла ...  Наука и техника   \n",
       "711456  Орангутан из Бангкокского зоопарка в Таиланде ...         Из жизни   \n",
       "733934  Бывший полузащитник «Барселоны» и сборной Браз...            Спорт   \n",
       "452612  Группа Tequilajazzz перезапишет альбом «Целлул...         Культура   \n",
       "180927  22 января в Таллине откроется Европейский конг...      Бывший СССР   \n",
       "491914  Приложение для чтения электронных книг FBReade...  Наука и техника   \n",
       "112313  \"Юганскнефтегаз\" уже направил в Министерство п...        Экономика   \n",
       "107     \"Инкомбанк\" добился приостановления дела о его...           Россия   \n",
       "288524  Джоанна Лопяновски-Робертс, живущая в США урож...         Культура   \n",
       "478790  Галерею «Культурный Альянс. Проект Марата Гель...         Культура   \n",
       "\n",
       "             tags        date  \n",
       "610286      Наука  2016/08/02  \n",
       "711456      Звери  2018/05/03  \n",
       "733934     Футбол  2018/11/06  \n",
       "452612     Музыка  2013/01/30  \n",
       "180927        Все  2007/02/21  \n",
       "491914    Гаджеты  2013/12/24  \n",
       "112313        Все  2005/02/11  \n",
       "107           Все  1999/09/07  \n",
       "288524        Все  2009/06/26  \n",
       "478790  Искусство  2013/09/06  "
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# search nearest with simple distancing\n",
    "distances = pairwise_distances(np.array(list(w2v_request_emb.values)), np.array(list(w2v_embs.values)), metric='cosine').flatten()\n",
    "distances = pd.Series(distances, index=prepared.index)      # restore index\n",
    "\n",
    "sorted_distances = distances.sort_values(ascending=False)\n",
    "# top 10 news\n",
    "top = sorted_distances[:10].index\n",
    "# overview\n",
    "news.loc[top]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__FastText__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>topic</th>\n",
       "      <th>tags</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14807</th>\n",
       "      <td>https://lenta.ru/news/2000/10/17/visas/</td>\n",
       "      <td>Чехия переходит на визовый режим со всеми стра...</td>\n",
       "      <td>C 22 октября Чехия вводит визовый пограничный ...</td>\n",
       "      <td>Мир</td>\n",
       "      <td>Все</td>\n",
       "      <td>2000/10/17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1672</th>\n",
       "      <td>https://lenta.ru/news/1999/11/15/mazeikiu/</td>\n",
       "      <td>Остановлен единственный нефтезавод в странах Б...</td>\n",
       "      <td>Производство на нефтеперерабатывающем заводе M...</td>\n",
       "      <td>Экономика</td>\n",
       "      <td>Все</td>\n",
       "      <td>1999/11/15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16663</th>\n",
       "      <td>https://lenta.ru/news/2000/11/18/bitum/</td>\n",
       "      <td>Пожар на битумном заводе тушили больше часа</td>\n",
       "      <td>Сильный пожар произошел во второй половине дня...</td>\n",
       "      <td>Россия</td>\n",
       "      <td>Все</td>\n",
       "      <td>2000/11/18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14985</th>\n",
       "      <td>https://lenta.ru/news/2000/10/20/potter_frodo/</td>\n",
       "      <td>Гарри Поттер померяется силами с Фродо и Гэнда...</td>\n",
       "      <td>Эдриан Бюрн, руководитель отдела продаж издате...</td>\n",
       "      <td>Культура</td>\n",
       "      <td>Все</td>\n",
       "      <td>2000/10/20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22120</th>\n",
       "      <td>https://lenta.ru/news/2001/02/20/angel/</td>\n",
       "      <td>Больничная сиделка призналась, что убивала сво...</td>\n",
       "      <td>23-летняя больничная сиделка, прозванная \"черн...</td>\n",
       "      <td>Мир</td>\n",
       "      <td>Все</td>\n",
       "      <td>2001/02/20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21681</th>\n",
       "      <td>https://lenta.ru/news/2001/02/12/protest/</td>\n",
       "      <td>Полиция арестовала 325 шотландцев за борьбу с ...</td>\n",
       "      <td>В понедельник толпа шотландцев блокировала вхо...</td>\n",
       "      <td>Мир</td>\n",
       "      <td>Все</td>\n",
       "      <td>2001/02/12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8705</th>\n",
       "      <td>https://lenta.ru/news/2000/06/08/baraev/</td>\n",
       "      <td>Манилов знает, где искать Басаева</td>\n",
       "      <td>По данным военных, чеченский полевой командир ...</td>\n",
       "      <td>Россия</td>\n",
       "      <td>Все</td>\n",
       "      <td>2000/06/08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23991</th>\n",
       "      <td>https://lenta.ru/news/2001/03/26/investment/</td>\n",
       "      <td>Об иностранных инвесторах в Белоруссии позабот...</td>\n",
       "      <td>Белорусские службы безопасности решили гаранти...</td>\n",
       "      <td>Мир</td>\n",
       "      <td>Все</td>\n",
       "      <td>2001/03/26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23518</th>\n",
       "      <td>https://lenta.ru/news/2001/03/18/gantamirov/</td>\n",
       "      <td>В Ингушетии задержан похититель людей</td>\n",
       "      <td>В субботу вечером в Ингушетии задержан житель ...</td>\n",
       "      <td>Россия</td>\n",
       "      <td>Все</td>\n",
       "      <td>2001/03/18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2852</th>\n",
       "      <td>https://lenta.ru/news/1999/12/23/cherkesia/</td>\n",
       "      <td>В Карачаево-Черкесии подтасовали результаты вы...</td>\n",
       "      <td>В четверг прокуратурой Карачаево-Черкесии было...</td>\n",
       "      <td>Россия</td>\n",
       "      <td>Все</td>\n",
       "      <td>1999/12/23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  url  \\\n",
       "14807         https://lenta.ru/news/2000/10/17/visas/   \n",
       "1672       https://lenta.ru/news/1999/11/15/mazeikiu/   \n",
       "16663         https://lenta.ru/news/2000/11/18/bitum/   \n",
       "14985  https://lenta.ru/news/2000/10/20/potter_frodo/   \n",
       "22120         https://lenta.ru/news/2001/02/20/angel/   \n",
       "21681       https://lenta.ru/news/2001/02/12/protest/   \n",
       "8705         https://lenta.ru/news/2000/06/08/baraev/   \n",
       "23991    https://lenta.ru/news/2001/03/26/investment/   \n",
       "23518    https://lenta.ru/news/2001/03/18/gantamirov/   \n",
       "2852      https://lenta.ru/news/1999/12/23/cherkesia/   \n",
       "\n",
       "                                                   title  \\\n",
       "14807  Чехия переходит на визовый режим со всеми стра...   \n",
       "1672   Остановлен единственный нефтезавод в странах Б...   \n",
       "16663        Пожар на битумном заводе тушили больше часа   \n",
       "14985  Гарри Поттер померяется силами с Фродо и Гэнда...   \n",
       "22120  Больничная сиделка призналась, что убивала сво...   \n",
       "21681  Полиция арестовала 325 шотландцев за борьбу с ...   \n",
       "8705                   Манилов знает, где искать Басаева   \n",
       "23991  Об иностранных инвесторах в Белоруссии позабот...   \n",
       "23518              В Ингушетии задержан похититель людей   \n",
       "2852   В Карачаево-Черкесии подтасовали результаты вы...   \n",
       "\n",
       "                                                    text      topic tags  \\\n",
       "14807  C 22 октября Чехия вводит визовый пограничный ...        Мир  Все   \n",
       "1672   Производство на нефтеперерабатывающем заводе M...  Экономика  Все   \n",
       "16663  Сильный пожар произошел во второй половине дня...     Россия  Все   \n",
       "14985  Эдриан Бюрн, руководитель отдела продаж издате...   Культура  Все   \n",
       "22120  23-летняя больничная сиделка, прозванная \"черн...        Мир  Все   \n",
       "21681  В понедельник толпа шотландцев блокировала вхо...        Мир  Все   \n",
       "8705   По данным военных, чеченский полевой командир ...     Россия  Все   \n",
       "23991  Белорусские службы безопасности решили гаранти...        Мир  Все   \n",
       "23518  В субботу вечером в Ингушетии задержан житель ...     Россия  Все   \n",
       "2852   В четверг прокуратурой Карачаево-Черкесии было...     Россия  Все   \n",
       "\n",
       "             date  \n",
       "14807  2000/10/17  \n",
       "1672   1999/11/15  \n",
       "16663  2000/11/18  \n",
       "14985  2000/10/20  \n",
       "22120  2001/02/20  \n",
       "21681  2001/02/12  \n",
       "8705   2000/06/08  \n",
       "23991  2001/03/26  \n",
       "23518  2001/03/18  \n",
       "2852   1999/12/23  "
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FastText init\n",
    "vecsize = 300\n",
    "ft = FastText(sentences, vector_size=vecsize, min_count=20, seed=31)\n",
    "# build embeddings\n",
    "ft_embs = sentences.apply(lambda row: np.mean([ft.wv[word] for word in row if word in ft.wv], axis=0))\n",
    "\n",
    "# calc request embedding\n",
    "ft_request_emb = request[field].apply(lambda row: np.array([ft.wv[word] for word in row if word in ft.wv]).mean(axis=0))\n",
    "\n",
    "# build w2v cluster map\n",
    "ft_cluster = AnnoyIndex(vecsize ,'angular')\n",
    "for idx, item in enumerate(w2v_embs):\n",
    "    ft_cluster.add_item(idx, item)\n",
    "\n",
    "ft_cluster.build(10, n_jobs=-1)\n",
    "\n",
    "# get top nearest\n",
    "top = ft_cluster.get_nns_by_vector(ft_request_emb[0], 10)\n",
    "news.loc[top]\n",
    "# NOTE можно дополнительно сделать отбор или ранжирование кандидатов по топкику"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>topic</th>\n",
       "      <th>tags</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>248000</th>\n",
       "      <td>https://lenta.ru/news/2008/09/29/digg/</td>\n",
       "      <td>Digg оценили в 175 миллионов долларов</td>\n",
       "      <td>В ходе последнего раунда финансирования социал...</td>\n",
       "      <td>Интернет и СМИ</td>\n",
       "      <td>Все</td>\n",
       "      <td>2008/09/29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114701</th>\n",
       "      <td>https://lenta.ru/news/2005/03/11/oil/</td>\n",
       "      <td>Кудрин не дал Фрадкову снизить НДС</td>\n",
       "      <td>Налог на добавленную стоимость в ближайшие три...</td>\n",
       "      <td>Экономика</td>\n",
       "      <td>Все</td>\n",
       "      <td>2005/03/11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470185</th>\n",
       "      <td>https://lenta.ru/news/2013/06/24/quest/</td>\n",
       "      <td>Dragon Quest X выпустят на PC</td>\n",
       "      <td>Square Enix выпустит версию MMORPG Dragon Ques...</td>\n",
       "      <td>Наука и техника</td>\n",
       "      <td>Игры</td>\n",
       "      <td>2013/06/24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16222</th>\n",
       "      <td>https://lenta.ru/news/2000/11/10/british/</td>\n",
       "      <td>British Telecom поделят и продадут</td>\n",
       "      <td>Ведущая телекоммуникационная компания Великобр...</td>\n",
       "      <td>Экономика</td>\n",
       "      <td>Все</td>\n",
       "      <td>2000/11/10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446367</th>\n",
       "      <td>https://lenta.ru/news/2012/12/08/yakzags/</td>\n",
       "      <td>Якутам запретили пить в ЗАГСе</td>\n",
       "      <td>Территорию управления ЗАГСа при правительстве ...</td>\n",
       "      <td>Россия</td>\n",
       "      <td>Все</td>\n",
       "      <td>2012/12/08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254845</th>\n",
       "      <td>https://lenta.ru/news/2008/11/13/supreme/</td>\n",
       "      <td>Square Enix выпустит Supreme Commander 2</td>\n",
       "      <td>Издательство Square Enix заключило партнерское...</td>\n",
       "      <td>Наука и техника</td>\n",
       "      <td>Все</td>\n",
       "      <td>2008/11/13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130166</th>\n",
       "      <td>https://lenta.ru/news/2005/09/13/sell/</td>\n",
       "      <td>Ford Motor продает Hertz за 5,6 миллиарда долл...</td>\n",
       "      <td>Концерн Ford Motor продает свое подразделение ...</td>\n",
       "      <td>Экономика</td>\n",
       "      <td>Все</td>\n",
       "      <td>2005/09/13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455275</th>\n",
       "      <td>https://lenta.ru/news/2013/02/20/amnesia/</td>\n",
       "      <td>Сиквел Amnesia отложили</td>\n",
       "      <td>Инди-хоррор Amnesia: A Machine for Pigs отложи...</td>\n",
       "      <td>Наука и техника</td>\n",
       "      <td>Игры</td>\n",
       "      <td>2013/02/20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677832</th>\n",
       "      <td>https://lenta.ru/news/2017/08/16/tom/</td>\n",
       "      <td>Tom Ford дал маслу уда проявить себя в духах</td>\n",
       "      <td>Американская марка Tom Ford обновила парфюмерн...</td>\n",
       "      <td>Ценности</td>\n",
       "      <td>Внешний вид</td>\n",
       "      <td>2017/08/16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167613</th>\n",
       "      <td>https://lenta.ru/news/2006/10/09/symantec/</td>\n",
       "      <td>Symantec заработает на антивирусах 10 миллиард...</td>\n",
       "      <td>Главный исполнительный директор Symantec Джон ...</td>\n",
       "      <td>Интернет и СМИ</td>\n",
       "      <td>Все</td>\n",
       "      <td>2006/10/09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               url  \\\n",
       "248000      https://lenta.ru/news/2008/09/29/digg/   \n",
       "114701       https://lenta.ru/news/2005/03/11/oil/   \n",
       "470185     https://lenta.ru/news/2013/06/24/quest/   \n",
       "16222    https://lenta.ru/news/2000/11/10/british/   \n",
       "446367   https://lenta.ru/news/2012/12/08/yakzags/   \n",
       "254845   https://lenta.ru/news/2008/11/13/supreme/   \n",
       "130166      https://lenta.ru/news/2005/09/13/sell/   \n",
       "455275   https://lenta.ru/news/2013/02/20/amnesia/   \n",
       "677832       https://lenta.ru/news/2017/08/16/tom/   \n",
       "167613  https://lenta.ru/news/2006/10/09/symantec/   \n",
       "\n",
       "                                                    title  \\\n",
       "248000              Digg оценили в 175 миллионов долларов   \n",
       "114701                 Кудрин не дал Фрадкову снизить НДС   \n",
       "470185                      Dragon Quest X выпустят на PC   \n",
       "16222                  British Telecom поделят и продадут   \n",
       "446367                      Якутам запретили пить в ЗАГСе   \n",
       "254845           Square Enix выпустит Supreme Commander 2   \n",
       "130166  Ford Motor продает Hertz за 5,6 миллиарда долл...   \n",
       "455275                            Сиквел Amnesia отложили   \n",
       "677832       Tom Ford дал маслу уда проявить себя в духах   \n",
       "167613  Symantec заработает на антивирусах 10 миллиард...   \n",
       "\n",
       "                                                     text            topic  \\\n",
       "248000  В ходе последнего раунда финансирования социал...   Интернет и СМИ   \n",
       "114701  Налог на добавленную стоимость в ближайшие три...        Экономика   \n",
       "470185  Square Enix выпустит версию MMORPG Dragon Ques...  Наука и техника   \n",
       "16222   Ведущая телекоммуникационная компания Великобр...        Экономика   \n",
       "446367  Территорию управления ЗАГСа при правительстве ...           Россия   \n",
       "254845  Издательство Square Enix заключило партнерское...  Наука и техника   \n",
       "130166  Концерн Ford Motor продает свое подразделение ...        Экономика   \n",
       "455275  Инди-хоррор Amnesia: A Machine for Pigs отложи...  Наука и техника   \n",
       "677832  Американская марка Tom Ford обновила парфюмерн...         Ценности   \n",
       "167613  Главный исполнительный директор Symantec Джон ...   Интернет и СМИ   \n",
       "\n",
       "               tags        date  \n",
       "248000          Все  2008/09/29  \n",
       "114701          Все  2005/03/11  \n",
       "470185         Игры  2013/06/24  \n",
       "16222           Все  2000/11/10  \n",
       "446367          Все  2012/12/08  \n",
       "254845          Все  2008/11/13  \n",
       "130166          Все  2005/09/13  \n",
       "455275         Игры  2013/02/20  \n",
       "677832  Внешний вид  2017/08/16  \n",
       "167613          Все  2006/10/09  "
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# search nearest with simple distancing\n",
    "distances = pairwise_distances(np.array(list(ft_request_emb.values)), np.array(list(ft_embs.values)), metric='cosine').flatten()\n",
    "distances = pd.Series(distances, index=prepared.index)      # restore index\n",
    "\n",
    "sorted_distances = distances.sort_values(ascending=False)\n",
    "# top 10 news\n",
    "top = sorted_distances[:10].index\n",
    "# overview\n",
    "news.loc[top]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__why it doesn't work__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'спортивный'"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive = request[field][0][1]\n",
    "positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('адвокат', 0.9971103668212891),\n",
       " ('выпустить', 0.9970963597297668),\n",
       " ('бой', 0.9970950484275818),\n",
       " ('открыть', 0.9970911145210266),\n",
       " ('франция', 0.9970730543136597),\n",
       " ('сеть', 0.9970723390579224),\n",
       " ('отправить', 0.9970698356628418),\n",
       " ('газета', 0.9970691800117493),\n",
       " ('аэропорт', 0.9970670938491821),\n",
       " ('кубок', 0.9970661997795105)]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.wv.most_similar(positive, topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('свободный', 0.9999927878379822),\n",
       " ('местный', 0.9999927878379822),\n",
       " ('навальный', 0.9999926686286926),\n",
       " ('неизвестный', 0.999991238117218),\n",
       " ('незаконный', 0.9999908208847046),\n",
       " ('рекламный', 0.9999904036521912),\n",
       " ('социальный', 0.999988853931427),\n",
       " ('красный', 0.9999886155128479),\n",
       " ('секретный', 0.9999885559082031),\n",
       " ('частный', 0.9999882578849792)]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft.wv.most_similar(positive, topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очень интересные семнатические расстояния между словами получаются."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__пример классификатора топика__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 300)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select embeddings\n",
    "# embeddings = w2v_embs\n",
    "embeddings = ft_embs\n",
    "\n",
    "embeddings = np.array(list(embeddings.values))\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# кластеризатор по топикам\n",
    "idx2topic = dict(enumerate(prepared['topic'].unique()))\n",
    "topic2idx = {v: k for k,v in idx2topic.items()}\n",
    "\n",
    "true_labels = prepared['topic'].map(topic2idx)\n",
    "\n",
    "# train/valid split\n",
    "embs = pd.DataFrame(embeddings, index=true_labels.index)    # restore embedding indices\n",
    "train, valid = train_test_split(embs.index, test_size=0.2, stratify=true_labels, random_state=19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.04      0.07       198\n",
      "           1       0.34      0.44      0.38       905\n",
      "           2       0.39      0.49      0.43       553\n",
      "           3       0.66      0.54      0.59       431\n",
      "           4       0.25      0.19      0.22       357\n",
      "           5       0.00      0.00      0.00       139\n",
      "           6       0.33      0.55      0.41      1086\n",
      "           7       0.14      0.06      0.08       315\n",
      "           8       0.18      0.16      0.17       361\n",
      "           9       0.34      0.16      0.22       359\n",
      "          10       0.00      0.00      0.00        53\n",
      "          11       0.00      0.00      0.00        39\n",
      "          12       0.50      0.19      0.28       151\n",
      "          13       1.00      0.02      0.04        53\n",
      "\n",
      "    accuracy                           0.35      5000\n",
      "   macro avg       0.32      0.20      0.21      5000\n",
      "weighted avg       0.34      0.35      0.32      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fit classifier\n",
    "# model = BayesianGaussianMixture(n_components=len(topic2idx), n_init=1, random_state=17)\n",
    "# model = KNeighborsClassifier(n_neighbors=len(topic2idx), n_jobs=-1)\n",
    "# model = KMeans(n_clusters=len(topic2idx), random_state=17)\n",
    "model = LGBMClassifier(n_estimators=500, learning_rate=0.1, max_depth=5, num_leaves=31, n_jobs=-1, random_state=17)\n",
    "model.fit(embs.loc[train], true_labels[train])\n",
    "pred_labels = model.predict(embs.loc[valid])\n",
    "# print report\n",
    "report = classification_report(true_labels[valid], pred_labels)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingsDataset():\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X.reset_index(drop=True)\n",
    "        self.y = y.reset_index(drop=True)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X.loc[index].values, self.y.loc[index].values\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "\n",
    "class Cell(torch.nn.Module):\n",
    "    def __init__(self, inp, out, *, act=torch.relu, drop=0):\n",
    "        super().__init__()\n",
    "        self.linear = torch.nn.Linear(inp, out)\n",
    "        self.activation = act\n",
    "        self.bn = torch.nn.BatchNorm1d(out)\n",
    "        self.dp = torch.nn.Dropout(drop) if drop else None\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.bn(x)\n",
    "        if self.dp is not None:\n",
    "            x = self.dp(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, inp, out):\n",
    "        super().__init__()\n",
    "        self.cell1 = Cell(inp, 512, act=torch.relu, drop=0.1)\n",
    "        self.cell2 = Cell(512, 256, act=torch.relu, drop=0.1)\n",
    "        self.cell3 = Cell(256, out, act=torch.relu, drop=0.1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.cell1(x)\n",
    "        x = self.cell2(x)\n",
    "        x = self.cell3(x)\n",
    "        return torch.softmax(x, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5\n",
    "\n",
    "# init network\n",
    "device = 'cuda'\n",
    "net = Net(vecsize, len(topic2idx)).to(device)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
    "criterion = torch.nn.BCELoss()\n",
    "\n",
    "# make data loaders\n",
    "onehot_labels = pd.DataFrame(np.eye(true_labels.max() + 1)[true_labels.values], index=true_labels.index)\n",
    "emb_train_dataset = EmbeddingsDataset(embs.loc[train], onehot_labels.loc[train])\n",
    "emb_valid_dataset = EmbeddingsDataset(embs.loc[valid], onehot_labels.loc[train])\n",
    "train_loader = torch.utils.data.DataLoader(emb_train_dataset, batch_size=64, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(emb_valid_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 313/313 [00:04<00:00, 70.55it/s, cumulative loss per item=0.00505]\n",
      "Epoch 2/5: 100%|██████████| 313/313 [00:04<00:00, 70.90it/s, cumulative loss per item=0.00477]\n",
      "Epoch 3/5: 100%|██████████| 313/313 [00:04<00:00, 70.53it/s, cumulative loss per item=0.0047] \n",
      "Epoch 4/5: 100%|██████████| 313/313 [00:04<00:00, 71.35it/s, cumulative loss per item=0.00466]\n",
      "Epoch 5/5: 100%|██████████| 313/313 [00:04<00:00, 71.77it/s, cumulative loss per item=0.00463]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "net.train()\n",
    "for ep in range(EPOCHS):\n",
    "    sum_loss, items = 0.0, 0\n",
    "    pbar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f'Epoch {ep + 1}/{EPOCHS}')\n",
    "    for i, batch in pbar:\n",
    "        inputs, labels = batch[0].to(device).float(), batch[1].to(device).float()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        sum_loss += loss.item()\n",
    "        items += len(labels)\n",
    "        pbar.set_postfix({'cumulative loss per item': sum_loss / items})\n",
    "print('\\nDone.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/avagadro/anaconda3/envs/jupyter_default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/avagadro/anaconda3/envs/jupyter_default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.06      0.20      0.10       198\n",
      "           1       0.27      0.06      0.09       905\n",
      "           2       0.00      0.00      0.00       553\n",
      "           3       0.94      0.24      0.39       431\n",
      "           4       0.40      0.06      0.11       357\n",
      "           5       0.00      0.00      0.00       139\n",
      "           6       0.32      0.42      0.36      1086\n",
      "           7       0.01      0.00      0.01       315\n",
      "           8       0.14      0.21      0.17       361\n",
      "           9       0.02      0.01      0.01       359\n",
      "          10       0.03      0.47      0.06        53\n",
      "          11       0.00      0.00      0.00        39\n",
      "          12       0.08      0.50      0.14       151\n",
      "          13       0.00      0.00      0.00        53\n",
      "\n",
      "    accuracy                           0.17      5000\n",
      "   macro avg       0.16      0.16      0.10      5000\n",
      "weighted avg       0.25      0.17      0.16      5000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/avagadro/anaconda3/envs/jupyter_default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# evaluation\n",
    "net.eval()\n",
    "pred_labels = net(torch.as_tensor(embs.loc[valid].values, device=device)).detach().cpu().argmax(axis=1)\n",
    "report = classification_report(true_labels[valid], pred_labels)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('jupyter_default')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "23a8a6843721b26098060b435da282c6499d0f0384483463012990926fcfc80c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
