{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "К сожалению, у меня не хватит времени прикрутить сюда распределенную обработку, поэтому в работе использую только часть данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/avagadro/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/avagadro/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "import torch\n",
    "import pymorphy2 as pm2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from gensim.models import Word2Vec, FastText\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from joblib import parallel_backend, Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "from ast import literal_eval\n",
    "from sklearn.metrics import pairwise_distances, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__load data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>topic</th>\n",
       "      <th>tags</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://lenta.ru/news/1914/09/16/hungarnn/</td>\n",
       "      <td>1914. Русские войска вступили в пределы Венгрии</td>\n",
       "      <td>Бои у Сопоцкина и Друскеник закончились отступ...</td>\n",
       "      <td>Библиотека</td>\n",
       "      <td>Первая мировая</td>\n",
       "      <td>1914/09/16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://lenta.ru/news/1914/09/16/lermontov/</td>\n",
       "      <td>1914. Празднование столетия М.Ю. Лермонтова от...</td>\n",
       "      <td>Министерство народного просвещения, в виду про...</td>\n",
       "      <td>Библиотека</td>\n",
       "      <td>Первая мировая</td>\n",
       "      <td>1914/09/16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://lenta.ru/news/1914/09/17/nesteroff/</td>\n",
       "      <td>1914. Das ist Nesteroff!</td>\n",
       "      <td>Штабс-капитан П. Н. Нестеров на днях, увидев в...</td>\n",
       "      <td>Библиотека</td>\n",
       "      <td>Первая мировая</td>\n",
       "      <td>1914/09/17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://lenta.ru/news/1914/09/17/bulldogn/</td>\n",
       "      <td>1914. Бульдог-гонец под Льежем</td>\n",
       "      <td>Фотограф-корреспондент Daily Mirror рассказыва...</td>\n",
       "      <td>Библиотека</td>\n",
       "      <td>Первая мировая</td>\n",
       "      <td>1914/09/17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://lenta.ru/news/1914/09/18/zver/</td>\n",
       "      <td>1914. Под Люблином пойман швабский зверь</td>\n",
       "      <td>Лица, приехавшие в Варшаву из Люблина, передаю...</td>\n",
       "      <td>Библиотека</td>\n",
       "      <td>Первая мировая</td>\n",
       "      <td>1914/09/18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           url  \\\n",
       "0   https://lenta.ru/news/1914/09/16/hungarnn/   \n",
       "1  https://lenta.ru/news/1914/09/16/lermontov/   \n",
       "2  https://lenta.ru/news/1914/09/17/nesteroff/   \n",
       "3   https://lenta.ru/news/1914/09/17/bulldogn/   \n",
       "4       https://lenta.ru/news/1914/09/18/zver/   \n",
       "\n",
       "                                               title  \\\n",
       "0  1914. Русские войска вступили в пределы Венгрии     \n",
       "1  1914. Празднование столетия М.Ю. Лермонтова от...   \n",
       "2                           1914. Das ist Nesteroff!   \n",
       "3                    1914. Бульдог-гонец под Льежем    \n",
       "4           1914. Под Люблином пойман швабский зверь   \n",
       "\n",
       "                                                text       topic  \\\n",
       "0  Бои у Сопоцкина и Друскеник закончились отступ...  Библиотека   \n",
       "1  Министерство народного просвещения, в виду про...  Библиотека   \n",
       "2  Штабс-капитан П. Н. Нестеров на днях, увидев в...  Библиотека   \n",
       "3  Фотограф-корреспондент Daily Mirror рассказыва...  Библиотека   \n",
       "4  Лица, приехавшие в Варшаву из Люблина, передаю...  Библиотека   \n",
       "\n",
       "             tags        date  \n",
       "0  Первая мировая  1914/09/16  \n",
       "1  Первая мировая  1914/09/16  \n",
       "2  Первая мировая  1914/09/17  \n",
       "3  Первая мировая  1914/09/17  \n",
       "4  Первая мировая  1914/09/18  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news = pd.read_csv('data/lenta-ru-news.csv', dtype={'topic': str})\n",
    "news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 800975 entries, 0 to 800974\n",
      "Data columns (total 6 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   url     800975 non-null  object\n",
      " 1   title   800975 non-null  object\n",
      " 2   text    800970 non-null  object\n",
      " 3   topic   738973 non-null  object\n",
      " 4   tags    773756 non-null  object\n",
      " 5   date    800975 non-null  object\n",
      "dtypes: object(6)\n",
      "memory usage: 36.7+ MB\n"
     ]
    }
   ],
   "source": [
    "news.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__preprocessing__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обрабатывать обучающие данные проще пайплайном, но для единичных пользовательских запросов пайплайн в реализованном виде не очень удобен,\n",
    "т.к. требует конвертации в pd.DataFrame.\n",
    "\n",
    "Оптимальное решение пока не нашел, и чтобы не писать тут одни и те же предобработки, пользуюсь конвертацией единичного запроса. В проде такое, на мой взгляд, недопустимо."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicTransformer(TransformerMixin):\n",
    "    def __init__(self, fields, **kwargs):\n",
    "        self.fields = fields if isinstance(fields, list) else [fields]\n",
    "        self.backend = kwargs.pop('backend', 'loky')\n",
    "        self.n_jobs = kwargs.pop('n_jobs', -1)\n",
    "        for key, value in kwargs.items():\n",
    "            setattr(self, key, value)\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        if 'all' in self.fields:\n",
    "            self.fields = X.columns\n",
    "        self.fields = [col for col in self.fields if col in X.columns]\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        for f in self.fields:\n",
    "            X[f] = self.transform_column(X[f])\n",
    "        return X\n",
    "    \n",
    "    def transform_column(self, column):\n",
    "        return column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lowercase(BasicTransformer):\n",
    "    def transform_column(self, column):\n",
    "        print(f'Lowercase `{column.name}`')\n",
    "        return column.str.lower()\n",
    "\n",
    "class CutRegexp(BasicTransformer):\n",
    "    def transform_column(self, column):\n",
    "        print(f'Cut regexp `{column.name}`')\n",
    "        return column.str.replace(self.pattern, self.fill, regex=True)\n",
    "\n",
    "class Tokenize(BasicTransformer):\n",
    "    def transform_column(self, column):\n",
    "        with parallel_backend(self.backend, n_jobs=self.n_jobs):\n",
    "            result = Parallel()(delayed(self.tokenizer)(row) for row in tqdm(column.values, desc=f'tokenize `{column.name}`'))\n",
    "        return result\n",
    "\n",
    "class ClearStopwords(BasicTransformer):\n",
    "    def transform_column(self, column):\n",
    "        def _drop_stopwords(tokens):\n",
    "            # return [w for w in tokens if w not in self.stopwords]     # NOTE проверить, какой вариант быстрее\n",
    "            return list(set(tokens).difference(self.stopwords))\n",
    "\n",
    "        with parallel_backend(self.backend, n_jobs=self.n_jobs):\n",
    "            result = Parallel()(delayed(_drop_stopwords)(row) for row in tqdm(column.values, desc=f'clearing `{column.name}`'))\n",
    "        return result\n",
    "        # return column.apply(lambda tokens: [w for w in tokens if w not in self.stopwords])\n",
    "\n",
    "class Lemmatize(BasicTransformer):\n",
    "    morph = pm2.MorphAnalyzer()\n",
    "    def transform_column(self, column):\n",
    "        def _lemma(tokens):\n",
    "            return [self.morph.parse(w)[0].normal_form for w in tokens]\n",
    "\n",
    "        with parallel_backend(self.backend, n_jobs=self.n_jobs):\n",
    "            result = Parallel()(delayed(_lemma)(row) for row in tqdm(column.values, desc=f'lemmatize `{column.name}`'))\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init pipeline\n",
    "fields = ['title', 'text']\n",
    "pipeline = make_pipeline(\n",
    "    Lowercase(fields),\n",
    "    CutRegexp(fields, pattern=r'\\W|\\d', fill=' '),      # убрать спецсимволы и цифры\n",
    "    Tokenize(fields, tokenizer=nltk.tokenize.word_tokenize),\n",
    "    ClearStopwords(fields, stopwords=nltk.corpus.stopwords.words('russian')),\n",
    "    Lemmatize(fields)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare masks\n",
    "nans = news['text'].isna() | news['title'].isna()       # drop nan\n",
    "short = news['text'].str.split().str.len() < 10         # drop short texts - это очень тяжелая операция\n",
    "\n",
    "topics_mask = news['topic'].value_counts() > 5000       # select data with most frequent topics - это, опять же, для упрощения задачи\n",
    "topics = news['topic'].value_counts()[topics_mask].index\n",
    "use_topics = news['topic'].isin(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lowercase `title`\n",
      "Lowercase `text`\n",
      "Cut regexp `title`\n",
      "Cut regexp `text`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenize `title`: 100%|██████████| 25000/25000 [00:00<00:00, 49361.25it/s]\n",
      "tokenize `text`: 100%|██████████| 25000/25000 [00:04<00:00, 5860.22it/s]\n",
      "clearing `title`: 100%|██████████| 25000/25000 [00:02<00:00, 8793.43it/s]\n",
      "clearing `text`: 100%|██████████| 25000/25000 [00:01<00:00, 13610.60it/s]\n",
      "lemmatize `title`: 100%|██████████| 25000/25000 [11:18<00:00, 36.87it/s]\n",
      "lemmatize `text`: 100%|██████████| 25000/25000 [07:29<00:00, 55.56it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>topic</th>\n",
       "      <th>tags</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69783</th>\n",
       "      <td>https://lenta.ru/news/2003/04/23/teacher/</td>\n",
       "      <td>[хорватский, библиотека, домашний, учитель, ед...</td>\n",
       "      <td>[сосед, госпитализация, сообщать, ananova, пре...</td>\n",
       "      <td>Из жизни</td>\n",
       "      <td>Все</td>\n",
       "      <td>2003/04/23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69373</th>\n",
       "      <td>https://lenta.ru/news/2003/04/15/syria/</td>\n",
       "      <td>[буш, готовить, запретить, война, пентагон, си...</td>\n",
       "      <td>[вашингтон, эпизод, принятие, новый, однако, г...</td>\n",
       "      <td>Мир</td>\n",
       "      <td>Все</td>\n",
       "      <td>2003/04/15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722211</th>\n",
       "      <td>https://lenta.ru/news/2018/08/02/latte_for_pre...</td>\n",
       "      <td>[беременный, средство, вместо, кофе, канадка, ...</td>\n",
       "      <td>[чистить, развесить, заявить, однако, франчайз...</td>\n",
       "      <td>Из жизни</td>\n",
       "      <td>Люди</td>\n",
       "      <td>2018/08/02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240806</th>\n",
       "      <td>https://lenta.ru/news/2008/08/08/mechel1/</td>\n",
       "      <td>[акция, перенести, размещение, мечел, второй]</td>\n",
       "      <td>[потерять, акция, наметить, доллар, металлурги...</td>\n",
       "      <td>Экономика</td>\n",
       "      <td>Все</td>\n",
       "      <td>2008/08/08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190561</th>\n",
       "      <td>https://lenta.ru/news/2007/05/29/nba/</td>\n",
       "      <td>[вылет, оказаться, плей, андрей, ют, кириленко...</td>\n",
       "      <td>[сперс, забить, сборная, официальный, чужой, к...</td>\n",
       "      <td>Спорт</td>\n",
       "      <td>Все</td>\n",
       "      <td>2007/05/29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      url  \\\n",
       "69783           https://lenta.ru/news/2003/04/23/teacher/   \n",
       "69373             https://lenta.ru/news/2003/04/15/syria/   \n",
       "722211  https://lenta.ru/news/2018/08/02/latte_for_pre...   \n",
       "240806          https://lenta.ru/news/2008/08/08/mechel1/   \n",
       "190561              https://lenta.ru/news/2007/05/29/nba/   \n",
       "\n",
       "                                                    title  \\\n",
       "69783   [хорватский, библиотека, домашний, учитель, ед...   \n",
       "69373   [буш, готовить, запретить, война, пентагон, си...   \n",
       "722211  [беременный, средство, вместо, кофе, канадка, ...   \n",
       "240806      [акция, перенести, размещение, мечел, второй]   \n",
       "190561  [вылет, оказаться, плей, андрей, ют, кириленко...   \n",
       "\n",
       "                                                     text      topic  tags  \\\n",
       "69783   [сосед, госпитализация, сообщать, ananova, пре...   Из жизни   Все   \n",
       "69373   [вашингтон, эпизод, принятие, новый, однако, г...        Мир   Все   \n",
       "722211  [чистить, развесить, заявить, однако, франчайз...   Из жизни  Люди   \n",
       "240806  [потерять, акция, наметить, доллар, металлурги...  Экономика   Все   \n",
       "190561  [сперс, забить, сборная, официальный, чужой, к...      Спорт   Все   \n",
       "\n",
       "              date  \n",
       "69783   2003/04/23  \n",
       "69373   2003/04/15  \n",
       "722211  2018/08/02  \n",
       "240806  2008/08/08  \n",
       "190561  2007/05/29  "
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preprocess data sample: поскольку времени мало, беру очень маленькую часть данных\n",
    "data = news[~nans & ~short & use_topics].sample(25000, random_state=23)\n",
    "\n",
    "prepared = pipeline.fit_transform(data)\n",
    "prepared.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared.to_csv('data/prepared.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load saved\n",
    "prepared = pd.read_csv('data/prepared.csv', index_col='Unnamed: 0', converters={'title': literal_eval, 'text': literal_eval})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lowercase `title`\n",
      "Cut regexp `title`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenize `title`: 100%|██████████| 1/1 [00:00<00:00, 43.44it/s]\n",
      "clearing `title`: 100%|██████████| 1/1 [00:00<00:00, 1443.33it/s]\n",
      "lemmatize `title`: 100%|██████████| 1/1 [00:00<00:00, 878.57it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[россия, достижение, спортивный]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              title\n",
       "0  [россия, достижение, спортивный]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "field = 'title'\n",
    "# field = 'text'\n",
    "sentences = prepared[field]\n",
    "\n",
    "# request preprocess\n",
    "request_text = 'спортивные достижения России'\n",
    "request = pipeline.fit_transform(pd.DataFrame([request_text], columns=[field]))\n",
    "request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__word2vec__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 200)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# word2vec on titles\n",
    "w2v = Word2Vec(sentences, vector_size=200, window=7, min_count=1)\n",
    "# build title embeddings\n",
    "embeddings = sentences.apply(lambda row: np.mean([w2v.wv[word] for word in row if word in w2v.wv], axis=0))\n",
    "embeddings = np.array(list(embeddings.values))      # recast to np.array\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE можно сделать отбор или ранжирование кандидатов по топкику"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 200)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calc request embedding\n",
    "request_embedding = request[field].apply(lambda row: np.array([w2v.wv[word] for word in row if word in w2v.wv]).mean(axis=0))\n",
    "request_embedding = np.array(list(request_embedding.values))      # recast to np.array\n",
    "request_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>topic</th>\n",
       "      <th>tags</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8463</th>\n",
       "      <td>https://lenta.ru/news/2000/06/02/hockey/</td>\n",
       "      <td>Могильный забивает и проигрывает</td>\n",
       "      <td>Во втором матче финальной серии розыгрыша Кубк...</td>\n",
       "      <td>Спорт</td>\n",
       "      <td>Все</td>\n",
       "      <td>2000/06/02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180927</th>\n",
       "      <td>https://lenta.ru/news/2007/02/21/congress/</td>\n",
       "      <td>В Таллин съезжаются каббалисты</td>\n",
       "      <td>22 января в Таллине откроется Европейский конг...</td>\n",
       "      <td>Бывший СССР</td>\n",
       "      <td>Все</td>\n",
       "      <td>2007/02/21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288524</th>\n",
       "      <td>https://lenta.ru/news/2009/06/26/needlework/</td>\n",
       "      <td>Сикстинскую капеллу вышили крестиком</td>\n",
       "      <td>Джоанна Лопяновски-Робертс, живущая в США урож...</td>\n",
       "      <td>Культура</td>\n",
       "      <td>Все</td>\n",
       "      <td>2009/06/26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452612</th>\n",
       "      <td>https://lenta.ru/news/2013/01/30/tezzz/</td>\n",
       "      <td>Tequilajazzz воссоединится для перезаписи «Цел...</td>\n",
       "      <td>Группа Tequilajazzz перезапишет альбом «Целлул...</td>\n",
       "      <td>Культура</td>\n",
       "      <td>Музыка</td>\n",
       "      <td>2013/01/30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491914</th>\n",
       "      <td>https://lenta.ru/news/2013/12/24/fbreader/</td>\n",
       "      <td>YotaPhone подружили с читалкой FBReader</td>\n",
       "      <td>Приложение для чтения электронных книг FBReade...</td>\n",
       "      <td>Наука и техника</td>\n",
       "      <td>Гаджеты</td>\n",
       "      <td>2013/12/24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610286</th>\n",
       "      <td>https://lenta.ru/news/2016/08/02/mamont/</td>\n",
       "      <td>Мамонтов добила жажда</td>\n",
       "      <td>Последняя популяция мамонтов на Земле вымерла ...</td>\n",
       "      <td>Наука и техника</td>\n",
       "      <td>Наука</td>\n",
       "      <td>2016/08/02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711456</th>\n",
       "      <td>https://lenta.ru/news/2018/05/03/poslemayskih/</td>\n",
       "      <td>Орангутан загрустил в неволе и растолстел</td>\n",
       "      <td>Орангутан из Бангкокского зоопарка в Таиланде ...</td>\n",
       "      <td>Из жизни</td>\n",
       "      <td>Звери</td>\n",
       "      <td>2018/05/03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715295</th>\n",
       "      <td>https://lenta.ru/news/2018/06/05/newticket/</td>\n",
       "      <td>К брюкам пришили пошлый карман</td>\n",
       "      <td>Японская компания GU выбрала новое местоположе...</td>\n",
       "      <td>Ценности</td>\n",
       "      <td>Стиль</td>\n",
       "      <td>2018/06/05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733934</th>\n",
       "      <td>https://lenta.ru/news/2018/11/06/ronaldinho/</td>\n",
       "      <td>Роналдиньо подозрительно обеднел</td>\n",
       "      <td>Бывший полузащитник «Барселоны» и сборной Браз...</td>\n",
       "      <td>Спорт</td>\n",
       "      <td>Футбол</td>\n",
       "      <td>2018/11/06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735243</th>\n",
       "      <td>https://lenta.ru/news/2018/11/16/petrosyan/</td>\n",
       "      <td>Петросян и Степаненко развелись</td>\n",
       "      <td>Брак юмористов Евгения Петросяна и Елены Степа...</td>\n",
       "      <td>Интернет и СМИ</td>\n",
       "      <td>ТВ и радио</td>\n",
       "      <td>2018/11/16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   url  \\\n",
       "8463          https://lenta.ru/news/2000/06/02/hockey/   \n",
       "180927      https://lenta.ru/news/2007/02/21/congress/   \n",
       "288524    https://lenta.ru/news/2009/06/26/needlework/   \n",
       "452612         https://lenta.ru/news/2013/01/30/tezzz/   \n",
       "491914      https://lenta.ru/news/2013/12/24/fbreader/   \n",
       "610286        https://lenta.ru/news/2016/08/02/mamont/   \n",
       "711456  https://lenta.ru/news/2018/05/03/poslemayskih/   \n",
       "715295     https://lenta.ru/news/2018/06/05/newticket/   \n",
       "733934    https://lenta.ru/news/2018/11/06/ronaldinho/   \n",
       "735243     https://lenta.ru/news/2018/11/16/petrosyan/   \n",
       "\n",
       "                                                    title  \\\n",
       "8463                     Могильный забивает и проигрывает   \n",
       "180927                     В Таллин съезжаются каббалисты   \n",
       "288524               Сикстинскую капеллу вышили крестиком   \n",
       "452612  Tequilajazzz воссоединится для перезаписи «Цел...   \n",
       "491914            YotaPhone подружили с читалкой FBReader   \n",
       "610286                              Мамонтов добила жажда   \n",
       "711456          Орангутан загрустил в неволе и растолстел   \n",
       "715295                     К брюкам пришили пошлый карман   \n",
       "733934                   Роналдиньо подозрительно обеднел   \n",
       "735243                    Петросян и Степаненко развелись   \n",
       "\n",
       "                                                     text            topic  \\\n",
       "8463    Во втором матче финальной серии розыгрыша Кубк...            Спорт   \n",
       "180927  22 января в Таллине откроется Европейский конг...      Бывший СССР   \n",
       "288524  Джоанна Лопяновски-Робертс, живущая в США урож...         Культура   \n",
       "452612  Группа Tequilajazzz перезапишет альбом «Целлул...         Культура   \n",
       "491914  Приложение для чтения электронных книг FBReade...  Наука и техника   \n",
       "610286  Последняя популяция мамонтов на Земле вымерла ...  Наука и техника   \n",
       "711456  Орангутан из Бангкокского зоопарка в Таиланде ...         Из жизни   \n",
       "715295  Японская компания GU выбрала новое местоположе...         Ценности   \n",
       "733934  Бывший полузащитник «Барселоны» и сборной Браз...            Спорт   \n",
       "735243  Брак юмористов Евгения Петросяна и Елены Степа...   Интернет и СМИ   \n",
       "\n",
       "              tags        date  \n",
       "8463           Все  2000/06/02  \n",
       "180927         Все  2007/02/21  \n",
       "288524         Все  2009/06/26  \n",
       "452612      Музыка  2013/01/30  \n",
       "491914     Гаджеты  2013/12/24  \n",
       "610286       Наука  2016/08/02  \n",
       "711456       Звери  2018/05/03  \n",
       "715295       Стиль  2018/06/05  \n",
       "733934      Футбол  2018/11/06  \n",
       "735243  ТВ и радио  2018/11/16  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# search nearest\n",
    "distances = pairwise_distances(request_embedding, embeddings, metric='cosine').flatten()\n",
    "distances = pd.Series(distances, index=prepared.index)      # restore index\n",
    "\n",
    "sorted_distances = distances.sort_values(ascending=False)\n",
    "# top 10 news\n",
    "top = sorted_distances[:10].index\n",
    "# overview\n",
    "news.loc[top]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__FastText__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 500)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft = FastText(sentences, vector_size=500)\n",
    "# build title embeddings\n",
    "embeddings = sentences.apply(lambda row: np.mean([ft.wv[word] for word in row if word in ft.wv], axis=0))\n",
    "embeddings = np.array(embeddings.tolist())      # recast to np.array\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE можно сделать отбор или ранжирование кандидатов по топкику"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 500)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calc request embedding\n",
    "request_embedding = request[field].apply(lambda row: np.array([ft.wv[word] for word in row if word in ft.wv]).mean(axis=0))\n",
    "request_embedding = np.array(request_embedding.tolist())      # recast to np.array\n",
    "request_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>topic</th>\n",
       "      <th>tags</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31685</th>\n",
       "      <td>https://lenta.ru/news/2001/07/26/cbr/</td>\n",
       "      <td>Центробанк накопил 36 миллиардов долларов</td>\n",
       "      <td>Золотовалютные резервы России за период с 13 п...</td>\n",
       "      <td>Экономика</td>\n",
       "      <td>Все</td>\n",
       "      <td>2001/07/26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130166</th>\n",
       "      <td>https://lenta.ru/news/2005/09/13/sell/</td>\n",
       "      <td>Ford Motor продает Hertz за 5,6 миллиарда долл...</td>\n",
       "      <td>Концерн Ford Motor продает свое подразделение ...</td>\n",
       "      <td>Экономика</td>\n",
       "      <td>Все</td>\n",
       "      <td>2005/09/13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138667</th>\n",
       "      <td>https://lenta.ru/news/2005/12/16/invest/</td>\n",
       "      <td>Чубайс ликвидирует энергодефицит за 12 миллиар...</td>\n",
       "      <td>Глава РАО \"ЕЭС России\" Анатолий Чубайс намерен...</td>\n",
       "      <td>Экономика</td>\n",
       "      <td>Все</td>\n",
       "      <td>2005/12/16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160043</th>\n",
       "      <td>https://lenta.ru/news/2006/07/26/tehnosila/</td>\n",
       "      <td>\"Техносила\" построит себе склад за 100 миллион...</td>\n",
       "      <td>Торговая группа \"Техносила\" построит собственн...</td>\n",
       "      <td>Дом</td>\n",
       "      <td>Все</td>\n",
       "      <td>2006/07/26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167613</th>\n",
       "      <td>https://lenta.ru/news/2006/10/09/symantec/</td>\n",
       "      <td>Symantec заработает на антивирусах 10 миллиард...</td>\n",
       "      <td>Главный исполнительный директор Symantec Джон ...</td>\n",
       "      <td>Интернет и СМИ</td>\n",
       "      <td>Все</td>\n",
       "      <td>2006/10/09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246340</th>\n",
       "      <td>https://lenta.ru/news/2008/09/17/samsung/</td>\n",
       "      <td>Samsung предложил за SanDisk почти шесть милли...</td>\n",
       "      <td>Корейская корпорация Samsung Electronics предл...</td>\n",
       "      <td>Наука и техника</td>\n",
       "      <td>Все</td>\n",
       "      <td>2008/09/17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248000</th>\n",
       "      <td>https://lenta.ru/news/2008/09/29/digg/</td>\n",
       "      <td>Digg оценили в 175 миллионов долларов</td>\n",
       "      <td>В ходе последнего раунда финансирования социал...</td>\n",
       "      <td>Интернет и СМИ</td>\n",
       "      <td>Все</td>\n",
       "      <td>2008/09/29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443716</th>\n",
       "      <td>https://lenta.ru/news/2012/11/20/myspace/</td>\n",
       "      <td>На перезапуск MySpace попросят 50 миллионов до...</td>\n",
       "      <td>Холдинг Interactive Media, владеющий музыкальн...</td>\n",
       "      <td>Интернет и СМИ</td>\n",
       "      <td>Все</td>\n",
       "      <td>2012/11/20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590175</th>\n",
       "      <td>https://lenta.ru/news/2016/04/07/kubanbillion/</td>\n",
       "      <td>«Кубань» задолжала более миллиарда рублей</td>\n",
       "      <td>Долги краснодарского клуба «Кубань», выступающ...</td>\n",
       "      <td>Спорт</td>\n",
       "      <td>Футбол</td>\n",
       "      <td>2016/04/07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637519</th>\n",
       "      <td>https://lenta.ru/news/2016/12/26/veb/</td>\n",
       "      <td>ВЭБ предсказал себе 130 миллиардов рублей убытков</td>\n",
       "      <td>Внешэкономбанк по итогам года может получить у...</td>\n",
       "      <td>Экономика</td>\n",
       "      <td>Госэкономика</td>\n",
       "      <td>2016/12/26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   url  \\\n",
       "31685            https://lenta.ru/news/2001/07/26/cbr/   \n",
       "130166          https://lenta.ru/news/2005/09/13/sell/   \n",
       "138667        https://lenta.ru/news/2005/12/16/invest/   \n",
       "160043     https://lenta.ru/news/2006/07/26/tehnosila/   \n",
       "167613      https://lenta.ru/news/2006/10/09/symantec/   \n",
       "246340       https://lenta.ru/news/2008/09/17/samsung/   \n",
       "248000          https://lenta.ru/news/2008/09/29/digg/   \n",
       "443716       https://lenta.ru/news/2012/11/20/myspace/   \n",
       "590175  https://lenta.ru/news/2016/04/07/kubanbillion/   \n",
       "637519           https://lenta.ru/news/2016/12/26/veb/   \n",
       "\n",
       "                                                    title  \\\n",
       "31685           Центробанк накопил 36 миллиардов долларов   \n",
       "130166  Ford Motor продает Hertz за 5,6 миллиарда долл...   \n",
       "138667  Чубайс ликвидирует энергодефицит за 12 миллиар...   \n",
       "160043  \"Техносила\" построит себе склад за 100 миллион...   \n",
       "167613  Symantec заработает на антивирусах 10 миллиард...   \n",
       "246340  Samsung предложил за SanDisk почти шесть милли...   \n",
       "248000              Digg оценили в 175 миллионов долларов   \n",
       "443716  На перезапуск MySpace попросят 50 миллионов до...   \n",
       "590175          «Кубань» задолжала более миллиарда рублей   \n",
       "637519  ВЭБ предсказал себе 130 миллиардов рублей убытков   \n",
       "\n",
       "                                                     text            topic  \\\n",
       "31685   Золотовалютные резервы России за период с 13 п...        Экономика   \n",
       "130166  Концерн Ford Motor продает свое подразделение ...        Экономика   \n",
       "138667  Глава РАО \"ЕЭС России\" Анатолий Чубайс намерен...        Экономика   \n",
       "160043  Торговая группа \"Техносила\" построит собственн...              Дом   \n",
       "167613  Главный исполнительный директор Symantec Джон ...   Интернет и СМИ   \n",
       "246340  Корейская корпорация Samsung Electronics предл...  Наука и техника   \n",
       "248000  В ходе последнего раунда финансирования социал...   Интернет и СМИ   \n",
       "443716  Холдинг Interactive Media, владеющий музыкальн...   Интернет и СМИ   \n",
       "590175  Долги краснодарского клуба «Кубань», выступающ...            Спорт   \n",
       "637519  Внешэкономбанк по итогам года может получить у...        Экономика   \n",
       "\n",
       "                tags        date  \n",
       "31685            Все  2001/07/26  \n",
       "130166           Все  2005/09/13  \n",
       "138667           Все  2005/12/16  \n",
       "160043           Все  2006/07/26  \n",
       "167613           Все  2006/10/09  \n",
       "246340           Все  2008/09/17  \n",
       "248000           Все  2008/09/29  \n",
       "443716           Все  2012/11/20  \n",
       "590175        Футбол  2016/04/07  \n",
       "637519  Госэкономика  2016/12/26  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# search nearest\n",
    "distances = pairwise_distances(request_embedding, embeddings, metric='cosine').flatten()\n",
    "distances = pd.Series(distances, index=prepared.index)      # restore index\n",
    "\n",
    "sorted_distances = distances.sort_values(ascending=False)\n",
    "# top 10 news\n",
    "top = sorted_distances[:10].index\n",
    "# overview\n",
    "news.loc[top]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__why it doesn't work__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('второй', 0.9986008405685425),\n",
       " ('место', 0.9985744953155518),\n",
       " ('объяснить', 0.9985387921333313),\n",
       " ('рассказать', 0.9985325336456299),\n",
       " ('последний', 0.9985318183898926),\n",
       " ('матч', 0.9985306262969971),\n",
       " ('германия', 0.9985304474830627),\n",
       " ('реклама', 0.9985286593437195),\n",
       " ('оон', 0.9985216856002808),\n",
       " ('украинский', 0.9985213279724121)]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.wv.most_similar(request[field][0], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('агрессия', 0.9999939799308777),\n",
       " ('розовый', 0.9999921917915344),\n",
       " ('официальный', 0.9999920725822449),\n",
       " ('криминальный', 0.9999911189079285),\n",
       " ('белоруссия', 0.9999909400939941),\n",
       " ('россельхознадзор', 0.9999908804893494),\n",
       " ('роналдый', 0.9999907612800598),\n",
       " ('региональный', 0.9999905824661255),\n",
       " ('валютный', 0.9999904036521912),\n",
       " ('дешёвый', 0.9999901056289673)]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft.wv.most_similar(request[field][0], topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наипростейший вариант поиска ближайших эмбеддингов - по косинусному расстоянию - в данном случае работает неэффективно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__пример классификатора топика__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# кластеризатор по топикам\n",
    "idx2topic = dict(enumerate(prepared['topic'].unique()))\n",
    "topic2idx = {v: k for k,v in idx2topic.items()}\n",
    "\n",
    "true_labels = prepared['topic'].map(topic2idx)\n",
    "\n",
    "# train/valid split\n",
    "embs = pd.DataFrame(embeddings, index=true_labels.index)    # restore embedding indices\n",
    "train, valid = train_test_split(embs.index, test_size=0.2, stratify=true_labels, random_state=19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       198\n",
      "           1       0.33      0.45      0.38       905\n",
      "           2       0.37      0.46      0.41       553\n",
      "           3       0.61      0.49      0.54       431\n",
      "           4       0.27      0.23      0.25       357\n",
      "           5       0.00      0.00      0.00       139\n",
      "           6       0.34      0.56      0.42      1086\n",
      "           7       0.13      0.06      0.08       315\n",
      "           8       0.19      0.14      0.16       361\n",
      "           9       0.29      0.13      0.18       359\n",
      "          10       0.00      0.00      0.00        53\n",
      "          11       0.50      0.03      0.05        39\n",
      "          12       0.47      0.19      0.27       151\n",
      "          13       0.00      0.00      0.00        53\n",
      "\n",
      "    accuracy                           0.34      5000\n",
      "   macro avg       0.25      0.19      0.20      5000\n",
      "weighted avg       0.31      0.34      0.31      5000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/avagadro/anaconda3/envs/jupyter_default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/avagadro/anaconda3/envs/jupyter_default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/avagadro/anaconda3/envs/jupyter_default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.mixture import BayesianGaussianMixture, GaussianMixture\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# fit classifier\n",
    "# model = BayesianGaussianMixture(n_components=len(topic2idx), n_init=1, random_state=17)\n",
    "# model = KNeighborsClassifier(n_neighbors=len(topic2idx), n_jobs=-1)\n",
    "# model = KMeans(n_clusters=len(topic2idx), random_state=17)\n",
    "model = LGBMClassifier(n_estimators=500, learning_rate=0.1, max_depth=5, num_leaves=31, n_jobs=-1, random_state=17)\n",
    "model.fit(embs.loc[train], true_labels[train])\n",
    "pred_labels = model.predict(embs.loc[valid])\n",
    "# print report\n",
    "report = classification_report(true_labels[valid], pred_labels)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingsDataset():\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X.reset_index(drop=True)\n",
    "        self.y = y.reset_index(drop=True)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X.loc[index].values, self.y.loc[index].values\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "\n",
    "class Cell(torch.nn.Module):\n",
    "    def __init__(self, inp, out, *, act=torch.relu, drop=0):\n",
    "        super().__init__()\n",
    "        self.linear = torch.nn.Linear(inp, out)\n",
    "        self.activation = act\n",
    "        self.bn = torch.nn.BatchNorm1d(out)\n",
    "        self.dp = torch.nn.Dropout(drop) if drop else None\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.bn(x)\n",
    "        if self.dp is not None:\n",
    "            x = self.dp(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, inp, out):\n",
    "        super().__init__()\n",
    "        self.cell1 = Cell(inp, 512, act=torch.relu, drop=0.1)\n",
    "        self.cell2 = Cell(512, 256, act=torch.relu, drop=0.1)\n",
    "        self.cell3 = Cell(256, out, act=torch.tanh, drop=0.1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.cell1(x)\n",
    "        x = self.cell2(x)\n",
    "        x = self.cell3(x)\n",
    "        return torch.softmax(x, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5\n",
    "\n",
    "# init network\n",
    "device = 'cuda'\n",
    "net = Net(200, len(topic2idx)).to(device)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
    "criterion = torch.nn.BCELoss()\n",
    "\n",
    "# make data loaders\n",
    "onehot_labels = pd.DataFrame(np.eye(true_labels.max() + 1)[true_labels.values], index=true_labels.index)\n",
    "emb_train_dataset = EmbeddingsDataset(embs.loc[train], onehot_labels.loc[train])\n",
    "emb_valid_dataset = EmbeddingsDataset(embs.loc[valid], onehot_labels.loc[train])\n",
    "train_loader = torch.utils.data.DataLoader(emb_train_dataset, batch_size=64, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(emb_valid_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 313/313 [00:04<00:00, 71.64it/s, cumulative loss per item=0.00492]\n",
      "Epoch 2/5: 100%|██████████| 313/313 [00:04<00:00, 70.65it/s, cumulative loss per item=0.00479]\n",
      "Epoch 3/5: 100%|██████████| 313/313 [00:04<00:00, 68.14it/s, cumulative loss per item=0.00474]\n",
      "Epoch 4/5: 100%|██████████| 313/313 [00:04<00:00, 72.03it/s, cumulative loss per item=0.0047] \n",
      "Epoch 5/5: 100%|██████████| 313/313 [00:04<00:00, 69.06it/s, cumulative loss per item=0.00469]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "net.train()\n",
    "for ep in range(EPOCHS):\n",
    "    sum_loss, items = 0.0, 0\n",
    "    pbar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f'Epoch {ep + 1}/{EPOCHS}')\n",
    "    for i, batch in pbar:\n",
    "        inputs, labels = batch[0].to(device).float(), batch[1].to(device).float()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        sum_loss += loss.item()\n",
    "        items += len(labels)\n",
    "        pbar.set_postfix({'cumulative loss per item': sum_loss / items})\n",
    "print('\\nDone.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.06      0.42      0.11       198\n",
      "           1       0.26      0.11      0.16       905\n",
      "           2       0.32      0.44      0.37       553\n",
      "           3       0.29      0.65      0.40       431\n",
      "           4       0.00      0.00      0.00       357\n",
      "           5       0.03      0.07      0.05       139\n",
      "           6       0.34      0.02      0.04      1086\n",
      "           7       0.14      0.00      0.01       315\n",
      "           8       0.00      0.00      0.00       361\n",
      "           9       0.13      0.19      0.16       359\n",
      "          10       0.00      0.00      0.00        53\n",
      "          11       0.01      0.08      0.02        39\n",
      "          12       0.04      0.06      0.05       151\n",
      "          13       0.00      0.00      0.00        53\n",
      "\n",
      "    accuracy                           0.17      5000\n",
      "   macro avg       0.12      0.15      0.10      5000\n",
      "weighted avg       0.20      0.17      0.13      5000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/avagadro/anaconda3/envs/jupyter_default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/avagadro/anaconda3/envs/jupyter_default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/avagadro/anaconda3/envs/jupyter_default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# evaluation\n",
    "net.eval()\n",
    "pred_labels = net(torch.as_tensor(embs.loc[valid].values, device=device)).detach().cpu().argmax(axis=1)\n",
    "report = classification_report(true_labels[valid], pred_labels)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('jupyter_default')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "23a8a6843721b26098060b435da282c6499d0f0384483463012990926fcfc80c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
