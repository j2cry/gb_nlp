{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import pyconll\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk import tag\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import classification_report, precision_score\n",
    "\n",
    "from gensim.models import FastText\n",
    "\n",
    "DATA = pathlib.Path('data') / 'tags'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load (https://github.com/UniversalDependencies/UD_Russian-SynTagRus)\n",
    "train_raw = pyconll.iter_from_file(DATA / 'ru_syntagrus-ud-train-a.conllu')\n",
    "valid_raw = pyconll.iter_from_file(DATA / 'ru_syntagrus-ud-dev.conllu')\n",
    "\n",
    "# train/valid prepare\n",
    "# исходные данные содержат ошибки\n",
    "train = [[(token.form, token.upos) for token in sentence if token.upos] for sentence in train_raw]\n",
    "valid = [[(token.form, token.upos) for token in sentence if token.upos] for sentence in valid_raw]\n",
    "\n",
    "# train = [[(token.form, token.upos if token.upos else 'NO_TAG') for token in sentence] for sentence in train_raw]\n",
    "# valid = [[(token.form, token.upos if token.upos else 'NO_TAG') for token in sentence] for sentence in valid_raw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# проверка на None\n",
    "for n, sent in enumerate(train):\n",
    "    for token in sent:\n",
    "        if token[0] is None:\n",
    "            print(f'#{n}: has None token')\n",
    "        if token[1] is None:\n",
    "            print(f'#{n}: has None upos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# проверка на None\n",
    "for n, sent in enumerate(valid):\n",
    "    for token in sent:\n",
    "        if token[0] is None:\n",
    "            print(f'#{n}: has None token')\n",
    "        if token[1] is None:\n",
    "            print(f'#{n}: has None upos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__default tagging__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADJ</th>\n",
       "      <th>ADP</th>\n",
       "      <th>ADV</th>\n",
       "      <th>AUX</th>\n",
       "      <th>CCONJ</th>\n",
       "      <th>DET</th>\n",
       "      <th>INTJ</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>NUM</th>\n",
       "      <th>PART</th>\n",
       "      <th>PRON</th>\n",
       "      <th>PROPN</th>\n",
       "      <th>PUNCT</th>\n",
       "      <th>SCONJ</th>\n",
       "      <th>SYM</th>\n",
       "      <th>VERB</th>\n",
       "      <th>X</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>unigram</th>\n",
       "      <td>0.949051</td>\n",
       "      <td>0.996358</td>\n",
       "      <td>0.937281</td>\n",
       "      <td>0.822987</td>\n",
       "      <td>0.892897</td>\n",
       "      <td>0.892938</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.993293</td>\n",
       "      <td>0.887717</td>\n",
       "      <td>0.958795</td>\n",
       "      <td>0.868977</td>\n",
       "      <td>0.958674</td>\n",
       "      <td>0.568750</td>\n",
       "      <td>0.773733</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.988468</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.823466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bigram</th>\n",
       "      <td>0.950179</td>\n",
       "      <td>0.995835</td>\n",
       "      <td>0.948523</td>\n",
       "      <td>0.870830</td>\n",
       "      <td>0.953120</td>\n",
       "      <td>0.900887</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996152</td>\n",
       "      <td>0.884233</td>\n",
       "      <td>0.938561</td>\n",
       "      <td>0.876818</td>\n",
       "      <td>0.986184</td>\n",
       "      <td>0.403005</td>\n",
       "      <td>0.823565</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.976067</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.693670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trigram</th>\n",
       "      <td>0.919094</td>\n",
       "      <td>0.997784</td>\n",
       "      <td>0.943699</td>\n",
       "      <td>0.879776</td>\n",
       "      <td>0.945858</td>\n",
       "      <td>0.810033</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.995101</td>\n",
       "      <td>0.874656</td>\n",
       "      <td>0.955359</td>\n",
       "      <td>0.880085</td>\n",
       "      <td>0.994275</td>\n",
       "      <td>0.286398</td>\n",
       "      <td>0.839043</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.944337</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.505697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combo</th>\n",
       "      <td>0.951696</td>\n",
       "      <td>0.995631</td>\n",
       "      <td>0.942861</td>\n",
       "      <td>0.887384</td>\n",
       "      <td>0.952992</td>\n",
       "      <td>0.877184</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.993996</td>\n",
       "      <td>0.898977</td>\n",
       "      <td>0.943256</td>\n",
       "      <td>0.890181</td>\n",
       "      <td>0.965021</td>\n",
       "      <td>0.568750</td>\n",
       "      <td>0.842220</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.979816</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.828717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ADJ       ADP       ADV       AUX     CCONJ       DET      INTJ  \\\n",
       "unigram  0.949051  0.996358  0.937281  0.822987  0.892897  0.892938  1.000000   \n",
       "bigram   0.950179  0.995835  0.948523  0.870830  0.953120  0.900887  1.000000   \n",
       "trigram  0.919094  0.997784  0.943699  0.879776  0.945858  0.810033  0.545455   \n",
       "combo    0.951696  0.995631  0.942861  0.887384  0.952992  0.877184  1.000000   \n",
       "\n",
       "             NOUN       NUM      PART      PRON     PROPN     PUNCT     SCONJ  \\\n",
       "unigram  0.993293  0.887717  0.958795  0.868977  0.958674  0.568750  0.773733   \n",
       "bigram   0.996152  0.884233  0.938561  0.876818  0.986184  0.403005  0.823565   \n",
       "trigram  0.995101  0.874656  0.955359  0.880085  0.994275  0.286398  0.839043   \n",
       "combo    0.993996  0.898977  0.943256  0.890181  0.965021  0.568750  0.842220   \n",
       "\n",
       "         SYM      VERB         X  accuracy  \n",
       "unigram  1.0  0.988468  0.777778  0.823466  \n",
       "bigram   1.0  0.976067  0.666667  0.693670  \n",
       "trigram  1.0  0.944337  0.000000  0.505697  \n",
       "combo    1.0  0.979816  0.777778  0.828717  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = {}\n",
    "# unigram\n",
    "tagger = tag.UnigramTagger(train, backoff=tag.DefaultTagger('PUNCT'))\n",
    "metrics['unigram'] = tagger.precision(valid)     # evaluate is deprecated\n",
    "metrics['unigram']['accuracy'] = tagger.accuracy(valid)\n",
    "\n",
    "# bigram\n",
    "tagger = tag.BigramTagger(train, backoff=tag.DefaultTagger('PUNCT'))\n",
    "metrics['bigram'] = tagger.precision(valid)\n",
    "metrics['bigram']['accuracy'] = tagger.accuracy(valid)\n",
    "\n",
    "# trigram\n",
    "tagger = tag.TrigramTagger(train, backoff=tag.DefaultTagger('PUNCT'))\n",
    "metrics['trigram'] = tagger.precision(valid)\n",
    "metrics['trigram']['accuracy'] = tagger.accuracy(valid)\n",
    "\n",
    "# combined\n",
    "def backoff_tagger(sents, tagger_classes, backoff=None):\n",
    "    for cls in tagger_classes:\n",
    "        backoff = cls(sents, backoff=backoff)\n",
    "    return backoff\n",
    "\n",
    "tagger = backoff_tagger(train, [tag.UnigramTagger, tag.BigramTagger, tag.TrigramTagger], backoff=tag.DefaultTagger('PUNCT'))\n",
    "metrics['combo'] = tagger.precision(valid)\n",
    "metrics['combo']['accuracy'] = tagger.accuracy(valid)\n",
    "\n",
    "# precision comparison\n",
    "pd.DataFrame(metrics).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__custom tagger__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# разделение на tokens и tags\n",
    "tokens = {\n",
    "    'train': [token[0] for sentence in train for token in sentence],\n",
    "    'valid': [token[0] for sentence in valid for token in sentence]\n",
    "}\n",
    "tags = {\n",
    "    'train': [token[1] for sentence in train for token in sentence],\n",
    "    'valid': [token[1] for sentence in valid for token in sentence]\n",
    "}\n",
    "\n",
    "# подготовка тренировочного корпуса для FastText\n",
    "corpus = {\n",
    "    'train': [[token[0] for token in sent] for sent in train],\n",
    "    'valid': [[token[0] for token in sent] for sent in valid]\n",
    "}\n",
    "corp_tags = {\n",
    "    'train': [[token[1] for token in sent] for sent in train],\n",
    "    'valid': [[token[1] for token in sent] for sent in valid]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# подготовка FT и получение эмбеддингов слов\n",
    "ft = FastText(corpus['train'], vector_size=200, window=5, min_count=2)\n",
    "embeddings = {key: np.array([ft.wv[token] for token in values]) for key, values in tokens.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# кодируем теги\n",
    "le = LabelEncoder()\n",
    "lb = {\n",
    "    'train': le.fit_transform(tags['train']),\n",
    "    'valid': le.transform(tags['valid'])\n",
    "}\n",
    "\n",
    "labels = {\n",
    "    'train': np.eye(lb['train'].max() + 1)[lb['train']],\n",
    "    'valid': np.eye(lb['valid'].max() + 1)[lb['valid']],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare train/valid vectorized data\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 3), analyzer='char', max_df=1.0, max_features=300)\n",
    "# vectorizer = TfidfVectorizer(ngram_range=(1, 3), analyzer='char', max_df=1.0, max_features=300)\n",
    "matrix = {\n",
    "    'train': vectorizer.fit_transform(tokens['train']),\n",
    "    'valid': vectorizer.transform(tokens['valid'])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat features\n",
    "features = {\n",
    "    'train': np.hstack([embeddings['train'], matrix['train'].toarray()]),\n",
    "    'valid': np.hstack([embeddings['valid'], matrix['valid'].toarray()])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.76      0.78     15103\n",
      "           1       0.95      0.93      0.94     13717\n",
      "           2       0.74      0.58      0.65      7783\n",
      "           3       0.67      0.60      0.63      1390\n",
      "           4       0.77      0.97      0.86      5672\n",
      "           5       0.73      0.52      0.61      4265\n",
      "           6       0.00      0.00      0.00        24\n",
      "           7       0.79      0.88      0.83     36238\n",
      "           8       0.68      0.64      0.66      1734\n",
      "           9       0.61      0.64      0.62      5125\n",
      "          10       0.58      0.77      0.66      7444\n",
      "          11       0.58      0.38      0.46      5473\n",
      "          12       0.99      0.99      0.99     29186\n",
      "          13       0.30      0.20      0.24      2865\n",
      "          14       0.06      0.03      0.04        62\n",
      "          15       0.80      0.73      0.76     17110\n",
      "          16       0.06      0.08      0.07       134\n",
      "\n",
      "    accuracy                           0.81    153325\n",
      "   macro avg       0.59      0.57      0.58    153325\n",
      "weighted avg       0.80      0.81      0.80    153325\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fit LGBM\n",
    "model = LGBMClassifier(n_estimators=50, num_leaves=23, random_state=17)\n",
    "model.fit(features['train'], lb['train'])\n",
    "\n",
    "# evaluate\n",
    "lb_pred = model.predict(features['valid'])\n",
    "print(classification_report(lb['valid'], lb_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__NN approach__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "from common import TaggerDataset, TorchTrainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetLSTM(torch.nn.Module, TorchTrainable):\n",
    "    def __init__(self, inp, dim, out, drop=0.2, layers=2):\n",
    "        super().__init__()\n",
    "        self.lstm = torch.nn.LSTM(inp, dim, num_layers=layers, batch_first=True, bidirectional=True, dropout=0.2)\n",
    "        self.linear = torch.nn.Linear(2*dim, out)\n",
    "        self.dp = torch.nn.Dropout(drop)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x, ht = self.lstm(x)\n",
    "        x = self.dp(x)\n",
    "        x = self.linear(x)\n",
    "        x = torch.softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: 100%|██████████| 1663/1663 [01:21<00:00, 20.37it/s, cumulative loss per item=0.00937]\n",
      "Epoch 2/3: 100%|██████████| 1663/1663 [01:20<00:00, 20.57it/s, cumulative loss per item=0.00889]\n",
      "Epoch 3/3: 100%|██████████| 1663/1663 [01:20<00:00, 20.61it/s, cumulative loss per item=0.00855]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 256\n",
    "\n",
    "train_dataset = TaggerDataset(features['train'], labels['train'], dtype=torch.float)\n",
    "valid_dataset = TaggerDataset(features['valid'], labels['valid'], dtype=torch.float)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Selected device: {device}')\n",
    "net = NetLSTM(inp=500, dim=256, out=le.classes_.size, drop=0.2, layers=2).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "net.fit(train_loader, optimizer, criterion, epochs=3, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.77      0.81     15103\n",
      "           1       1.00      0.94      0.97     13717\n",
      "           2       0.71      0.79      0.75      7783\n",
      "           3       0.00      0.00      0.00      1390\n",
      "           4       0.87      0.99      0.92      5672\n",
      "           5       0.90      0.60      0.72      4265\n",
      "           6       0.00      0.00      0.00        24\n",
      "           7       0.78      0.96      0.86     36238\n",
      "           8       0.47      0.59      0.52      1734\n",
      "           9       0.89      0.70      0.79      5125\n",
      "          10       0.69      0.98      0.81      7444\n",
      "          11       0.00      0.00      0.00      5473\n",
      "          12       1.00      1.00      1.00     29186\n",
      "          13       0.00      0.00      0.00      2865\n",
      "          14       0.00      0.00      0.00        62\n",
      "          15       0.81      0.85      0.83     17110\n",
      "          16       0.00      0.00      0.00       134\n",
      "\n",
      "    accuracy                           0.84    153325\n",
      "   macro avg       0.53      0.54      0.53    153325\n",
      "weighted avg       0.80      0.84      0.82    153325\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/avagadro/anaconda3/envs/jupyter_default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/avagadro/anaconda3/envs/jupyter_default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/avagadro/anaconda3/envs/jupyter_default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "predicts = net.predict(valid_loader)\n",
    "lb_pred = predicts.argmax(axis=1)\n",
    "print(classification_report(lb['valid'], lb_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('jupyter_default')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "23a8a6843721b26098060b435da282c6499d0f0384483463012990926fcfc80c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
