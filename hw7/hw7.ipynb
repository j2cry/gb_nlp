{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import sys\n",
    "\n",
    "root = pathlib.Path().cwd()\n",
    "while not root.joinpath('.projectroot').exists():\n",
    "    root = root.parent\n",
    "\n",
    "sys.path.append(root.as_posix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from functools import partial\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import BertTokenizerFast\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from hw5.common import TorchTrainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Content</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>It just works!</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>В целом удобноное приложение...из минусов хотя...</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Отлично все</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Стал зависать на 1% работы антивируса. Дальше ...</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Очень удобно, работает быстро.</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating                                            Content        Date\n",
       "0       5                                     It just works!  2017-08-14\n",
       "1       4  В целом удобноное приложение...из минусов хотя...  2017-08-14\n",
       "2       5                                        Отлично все  2017-08-14\n",
       "3       5  Стал зависать на 1% работы антивируса. Дальше ...  2017-08-14\n",
       "4       5                     Очень удобно, работает быстро.  2017-08-14"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load pretrained model\n",
    "tokenizer = BertTokenizerFast.from_pretrained('blanchefort/rubert-base-cased-sentiment')\n",
    "model = AutoModelForSequenceClassification.from_pretrained('blanchefort/rubert-base-cased-sentiment', return_dict=True)\n",
    "\n",
    "# load & preprocess\n",
    "data = pd.read_excel('data/summer.xls')\n",
    "data = data[~data['Content'].isna()]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare\n",
    "features = data['Content'].astype(str).apply(partial(tokenizer, max_length=512, padding=True, truncation=True, return_tensors='pt'))\n",
    "\n",
    "def markup(x):\n",
    "    return 1 if x > 3 else 2 if x < 3 else 0\n",
    "rating = data['Rating'].apply(markup).values\n",
    "\n",
    "# split\n",
    "# X_train, X_valid, y_train, y_valid = train_test_split(features, rating, stratify=rating, random_state=17)\n",
    "train_index, valid_index = train_test_split(data.index, stratify=rating, random_state=17)\n",
    "train = data.index.isin(train_index)\n",
    "valid = data.index.isin(valid_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SummerDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, features, rating):\n",
    "        self.features = features\n",
    "        self.rating = np.eye(3)[rating]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # TODO concat with token_type_ids?\n",
    "        return self.features[index]['input_ids'], torch.as_tensor(self.rating[index].reshape(1, -1))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "train_dataset = SummerDataset(features[train].values, rating[train])\n",
    "valid_dataset = SummerDataset(features[valid].values, rating[valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertEmbeddings(\n",
       "  (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "  (position_embeddings): Embedding(512, 768)\n",
       "  (token_type_embeddings): Embedding(2, 768)\n",
       "  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.bert.embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module, TorchTrainable):\n",
    "    def __init__(self, mod=2, drop=0.1):\n",
    "        super().__init__()\n",
    "        self.embedding = model.bert.embeddings\n",
    "        # self.embedding = model.bert.embeddings.word_embeddings\n",
    "        self.conv = torch.nn.Conv1d(768, 768 * mod, kernel_size=2)\n",
    "\n",
    "        self.linear = torch.nn.Linear(768 * mod, 3)\n",
    "        self.dp = torch.nn.Dropout(drop)\n",
    "        \n",
    "    def forward(self, x):        \n",
    "        x = self.embedding(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.conv(x)\n",
    "        x = torch.relu(x)\n",
    "        x = torch.max_pool1d(x, 2)\n",
    "        x = self.dp(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.linear(x)\n",
    "        x = torch.softmax(x, dim=1)\n",
    "        return torch.mean(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.04      0.67      0.07       228\n",
      "           1       0.66      0.11      0.18      4180\n",
      "           2       0.32      0.14      0.19       756\n",
      "\n",
      "    accuracy                           0.14      5164\n",
      "   macro avg       0.34      0.30      0.15      5164\n",
      "weighted avg       0.59      0.14      0.18      5164\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# обученные эмбеддинги + необученная сетка\n",
    "net = Net().to('cuda')\n",
    "setattr(net, 'trained', True)\n",
    "setattr(net, 'dev', 'cuda')\n",
    "predicts = net.predict(valid_dataset)\n",
    "\n",
    "report = classification_report(rating[valid], predicts.argmax(axis=1))\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: 100%|██████████| 15492/15492 [12:54<00:00, 19.99it/s, cumulative loss per item=1.1]\n",
      "Epoch 2/3: 100%|██████████| 15492/15492 [12:36<00:00, 20.47it/s, cumulative loss per item=1.1]\n",
      "Epoch 3/3: 100%|██████████| 15492/15492 [12:46<00:00, 20.22it/s, cumulative loss per item=1.1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "net.to('cuda')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "net.fit(train_dataset, optimizer, criterion, epochs=3, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.03      0.61      0.06       228\n",
      "           1       0.70      0.12      0.20      4180\n",
      "           2       0.31      0.13      0.19       756\n",
      "\n",
      "    accuracy                           0.14      5164\n",
      "   macro avg       0.35      0.29      0.15      5164\n",
      "weighted avg       0.61      0.14      0.19      5164\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# обученные эмбеддинги + обученная сетка\n",
    "predicts = net.predict(valid_dataset)\n",
    "\n",
    "report = classification_report(rating[valid], predicts.argmax(axis=1))\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По 1-му классу есть прирост, но не сказал бы, что стало принципиально лучше. Направления работы:\n",
    "- очистка датасета (тут я его не чистил совсем)\n",
    "- усложнение архитектуры сети\n",
    "\n",
    "С tensorflow у меня по-прежнему нелюбовь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('jupyter_default')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "23a8a6843721b26098060b435da282c6499d0f0384483463012990926fcfc80c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
